{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hehe\n"
     ]
    }
   ],
   "source": [
    "print('hehe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\nimport numpy as np\\nimport time\\nimport math \\n\\ndef create_route(customer_nodes):\\n    route = customer_nodes[:]\\n    random.shuffle(route)\\n    return route\\n\\ndef get_n_neighbours(x, n, lower_bound, upper_bound):\\n    neighbors = set()\\n    while len(neighbors) < n:\\n        i, j = random.sample(range(len(x)), 2)\\n        neighbor = x.copy()\\n        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\\n        neighbors.add(tuple(neighbor)) \\n    return [list(neighbor) for neighbor in neighbors]\\n\\ndef create_multiple_routes(customer_nodes, n):\\n    routes = []\\n    unique_routes = set()\\n    \\n    while len(routes) < n:\\n        new_route = create_route(customer_nodes)\\n        route_tuple = tuple(new_route)\\n        \\n        if route_tuple not in unique_routes:\\n            unique_routes.add(route_tuple)\\n            routes.append(new_route)\\n    \\n    return routes\\n\\ndef generate_cost_matrix(num_nodes, num_customers, seed=None):\\n    if seed is not None:\\n        np.random.seed(seed)\\n        random.seed(seed)\\n\\n    grid_rows = num_customers#int(np.sqrt(num_nodes))\\n    grid_cols = grid_rows\\n    grid = np.arange(num_customers**2).reshape(grid_rows, grid_cols)\\n\\n    node_list = list(range(1, num_nodes))  # Exclude 0 as it\\'s the depot\\n\\n    def gen_node_list(node_list, num_customers):\\n        return random.sample(node_list, min(num_customers, len(node_list)))\\n\\n    customer_node_list = gen_node_list(node_list, num_customers)\\n\\n    def distcalc(customer_node_list):\\n        nodecoords = []\\n        nodecoords.append([0, 0])  # Starting point (depot)\\n        for node in customer_node_list:\\n            a, b = np.where(grid == node)\\n            nodecoords.append([a[0], b[0]])\\n\\n        distmat = np.zeros((len(nodecoords), len(nodecoords)))\\n        for i in range(len(nodecoords)):\\n            for j in range(len(nodecoords)):\\n                distmat[i, j] = abs(nodecoords[i][0] - nodecoords[j][0]) * 5 + abs(nodecoords[i][1] - nodecoords[j][1]) * 5\\n\\n        return distmat, customer_node_list\\n\\n    cost_matrix, customer_node_list = distcalc(customer_node_list)\\n\\n    return cost_matrix, customer_node_list\\n\\n# Generate the cost matrix and customer node list with a specific seed\\nCost_matrix, Customer_nodes = generate_cost_matrix(60, 10, seed=1234)\\nprint(\"Customer Nodes:\", Customer_nodes)\\nprint(\"Cost Matrix:\")\\nprint(Cost_matrix)\\n\\ndef SAR(k):\\n    n0=8\\n    return math.ceil(n0*(np.log(k)**2))\\nk = 2\\ndef stoichastic_cost_helper(route, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=None):\\n    if seed is not None:\\n        np.random.seed(seed)\\n\\n    total_cost = 0.0\\n    n = len(route)\\n    total_cost += cost_matrix[0][customer_nodes.index(route[0])] # depot to first customer\\n    for i in range(n):\\n        current_city = route[i]\\n        next_city = route[(i + 1) % n]\\n\\n        current_index = customer_nodes.index(current_city)\\n        next_index = customer_nodes.index(next_city)\\n\\n        original_cost = cost_matrix[current_index + 1][next_index + 1]  # +1 because 0 is depot\\n\\n        error_range = original_cost * (percentage / 100)\\n        new_cost = np.random.uniform(original_cost - error_range, original_cost + error_range)\\n        \\n        total_cost += new_cost\\n\\n    return total_cost\\n\\ndef stochastic_cost_function(route,n, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=42):\\n    global gas , k\\n    n = 7#SAR(k)\\n    gas += n#SAR(n)\\n    #print(gas)\\n    return np.mean([stoichastic_cost_helper(route, cost_matrix, customer_nodes, seed=seed) for _ in range(n)])\\n\\n# Initialize gas variable\\ngas = 0\\n\\n# Create an initial solution (route)\\ninitial_sol = Customer_nodes  # Use the generated customer nodes\\nprint(\"Initial Route:\", initial_sol)\\n\\n# Calculate the stochastic cost\\nstochastic_cost_value = stochastic_cost_function(initial_sol,n=SAR(k), cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, seed=42)\\nprint(\"Stochastic Cost:\", stochastic_cost_value)\\nprint(\"Gas used:\", gas)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math \n",
    "\n",
    "def create_route(customer_nodes):\n",
    "    route = customer_nodes[:]\n",
    "    random.shuffle(route)\n",
    "    return route\n",
    "\n",
    "def get_n_neighbours(x, n, lower_bound, upper_bound):\n",
    "    neighbors = set()\n",
    "    while len(neighbors) < n:\n",
    "        i, j = random.sample(range(len(x)), 2)\n",
    "        neighbor = x.copy()\n",
    "        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\n",
    "        neighbors.add(tuple(neighbor)) \n",
    "    return [list(neighbor) for neighbor in neighbors]\n",
    "\n",
    "def create_multiple_routes(customer_nodes, n):\n",
    "    routes = []\n",
    "    unique_routes = set()\n",
    "    \n",
    "    while len(routes) < n:\n",
    "        new_route = create_route(customer_nodes)\n",
    "        route_tuple = tuple(new_route)\n",
    "        \n",
    "        if route_tuple not in unique_routes:\n",
    "            unique_routes.add(route_tuple)\n",
    "            routes.append(new_route)\n",
    "    \n",
    "    return routes\n",
    "\n",
    "def generate_cost_matrix(num_nodes, num_customers, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    grid_rows = num_customers#int(np.sqrt(num_nodes))\n",
    "    grid_cols = grid_rows\n",
    "    grid = np.arange(num_customers**2).reshape(grid_rows, grid_cols)\n",
    "\n",
    "    node_list = list(range(1, num_nodes))  # Exclude 0 as it's the depot\n",
    "\n",
    "    def gen_node_list(node_list, num_customers):\n",
    "        return random.sample(node_list, min(num_customers, len(node_list)))\n",
    "\n",
    "    customer_node_list = gen_node_list(node_list, num_customers)\n",
    "\n",
    "    def distcalc(customer_node_list):\n",
    "        nodecoords = []\n",
    "        nodecoords.append([0, 0])  # Starting point (depot)\n",
    "        for node in customer_node_list:\n",
    "            a, b = np.where(grid == node)\n",
    "            nodecoords.append([a[0], b[0]])\n",
    "\n",
    "        distmat = np.zeros((len(nodecoords), len(nodecoords)))\n",
    "        for i in range(len(nodecoords)):\n",
    "            for j in range(len(nodecoords)):\n",
    "                distmat[i, j] = abs(nodecoords[i][0] - nodecoords[j][0]) * 5 + abs(nodecoords[i][1] - nodecoords[j][1]) * 5\n",
    "\n",
    "        return distmat, customer_node_list\n",
    "\n",
    "    cost_matrix, customer_node_list = distcalc(customer_node_list)\n",
    "\n",
    "    return cost_matrix, customer_node_list\n",
    "\n",
    "# Generate the cost matrix and customer node list with a specific seed\n",
    "Cost_matrix, Customer_nodes = generate_cost_matrix(60, 10, seed=1234)\n",
    "print(\"Customer Nodes:\", Customer_nodes)\n",
    "print(\"Cost Matrix:\")\n",
    "print(Cost_matrix)\n",
    "\n",
    "def SAR(k):\n",
    "    n0=8\n",
    "    return math.ceil(n0*(np.log(k)**2))\n",
    "k = 2\n",
    "def stoichastic_cost_helper(route, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    total_cost = 0.0\n",
    "    n = len(route)\n",
    "    total_cost += cost_matrix[0][customer_nodes.index(route[0])] # depot to first customer\n",
    "    for i in range(n):\n",
    "        current_city = route[i]\n",
    "        next_city = route[(i + 1) % n]\n",
    "\n",
    "        current_index = customer_nodes.index(current_city)\n",
    "        next_index = customer_nodes.index(next_city)\n",
    "\n",
    "        original_cost = cost_matrix[current_index + 1][next_index + 1]  # +1 because 0 is depot\n",
    "\n",
    "        error_range = original_cost * (percentage / 100)\n",
    "        new_cost = np.random.uniform(original_cost - error_range, original_cost + error_range)\n",
    "        \n",
    "        total_cost += new_cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def stochastic_cost_function(route,n, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=42):\n",
    "    global gas , k\n",
    "    n = 7#SAR(k)\n",
    "    gas += n#SAR(n)\n",
    "    #print(gas)\n",
    "    return np.mean([stoichastic_cost_helper(route, cost_matrix, customer_nodes, seed=seed) for _ in range(n)])\n",
    "\n",
    "# Initialize gas variable\n",
    "gas = 0\n",
    "\n",
    "# Create an initial solution (route)\n",
    "initial_sol = Customer_nodes  # Use the generated customer nodes\n",
    "print(\"Initial Route:\", initial_sol)\n",
    "\n",
    "# Calculate the stochastic cost\n",
    "stochastic_cost_value = stochastic_cost_function(initial_sol,n=SAR(k), cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, seed=42)\n",
    "print(\"Stochastic Cost:\", stochastic_cost_value)\n",
    "print(\"Gas used:\", gas)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER DEFINED VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound = 0\n",
    "up_bound = 100\n",
    "no_of_clusters =4\n",
    "solution_dimension = 2\n",
    "total_budget = 5e3\n",
    "alpha = 0.3\n",
    "no_of_neighbours = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12.297008723827798, 13.768973129834043],\n",
       " [10.266556454799206, 15.393844335139848],\n",
       " [15.413479014504137, 8.222965780571192],\n",
       " [0.0, 10.743633234680164],\n",
       " [5.9602628667893045, 14.252553016660666],\n",
       " [8.966304718776195, 14.506855992349646],\n",
       " [17.476566469004794, 9.950129905118084],\n",
       " [15.788742155076271, 9.026855500984958]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import math\n",
    "def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    y=0\n",
    "    noise = np.random.normal(0, 0.3)\n",
    "    for i in x:\n",
    "        y += ((np.sin(0.05*np.pi*i)**6)/(2**((2*(((i-10)/80)**2)))) + noise)\n",
    "    return -y \n",
    "#stochastic_cost_function(0)   \n",
    "def stochastic_cost_function(x:list[int],n:int = 10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])\n",
    "low_bound = 0\n",
    "up_bound = 100\n",
    "\n",
    "def get_n_neighbours(x: list[int], n: int = no_of_neighbours, lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    neighbors = []\n",
    "    for i in range(n):\n",
    "        reach = 5 * np.random.randn(1, len(x))  # normal distribution with 0 mean and 5 std\n",
    "        new_neighbor = np.clip(np.array(x) + reach[0], lower_bound, upper_bound)\n",
    "        neighbors.append(list(new_neighbor))\n",
    "    return neighbors\n",
    "k = 2\n",
    "def SAR(k):\n",
    "    \n",
    "    n0=8\n",
    "    return math.ceil(n0*(np.log(k)**2))\n",
    "get_n_neighbours([10,10],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_budget = 1e4\n",
    "GA_budget = 0\n",
    "compass_budget = 0\n",
    "def assign_budgets(total_budget,alpha =alpha):\n",
    "    global GA_budget , compass_budget\n",
    "    #alpha = 0.5\n",
    "    GA_budget = total_budget*alpha\n",
    "    compass_budget = total_budget*(1-alpha)\n",
    "assign_budgets(total_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 57, 26, 91]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import heapq\n",
    "#global gas \n",
    "gas = 0\n",
    "def create_genome(n,lower_bound =low_bound,upper_bound=up_bound):\n",
    "    return [np.random.randint(lower_bound,upper_bound) for _ in range(n)]\n",
    "print(create_genome(4))\n",
    "\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise'''\n",
    "#print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "'''def stochastic_cost_function(x:list[int],n:int=10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "\n",
    "def euclidean_distance(centre_1 : List[int],centre_2: List[int]):\n",
    "    array1 = np.array(centre_1)\n",
    "    array2 = np.array(centre_2)\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(array1 - array2)\n",
    "    return euclidean_distance\n",
    "\n",
    "def find_farthest_point(center: List[int], sol_space: List[List[int]]) -> Tuple[List[int], float]: #Finds the farthest point in the solution space from the centre\n",
    "    max_distance = 0\n",
    "    farthest_point = None\n",
    "    \n",
    "    for point in sol_space:\n",
    "        # Calculate the squared distance\n",
    "        squared_distance = sum((c - p)**2 for c, p in zip(center, point))\n",
    "        \n",
    "        if squared_distance > max_distance:\n",
    "            max_distance = squared_distance\n",
    "            farthest_point = point\n",
    "    \n",
    "    # Calculate the actual distance (square root of the squared distance)\n",
    "    max_distance = np.sqrt(max_distance)\n",
    "    \n",
    "    return farthest_point, max_distance\n",
    "\n",
    "def closeset_centre(centers:List[List[int]],visited_solution:List[int]) -> List[int]:#Finds the closests centre to the point\n",
    "    closest = [float('inf') for _ in centers]\n",
    "    min_dist= float('inf')\n",
    "    for center in centers:\n",
    "        dist =euclidean_distance(center,visited_solution)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = center\n",
    "        #print('hehe: ',closest)\n",
    "    return closest\n",
    "#INITIALIZATION STEP\n",
    "def initialize(mg:int,q:int = no_of_clusters,n:int = solution_dimension) : #n is dimension of solution vector and mg is number of solns sampled\n",
    "    #n=4\n",
    "    global gas,k\n",
    "    unique_set = {}\n",
    "    while len(unique_set) <mg: # Sampling Mg Solutions from the feasible set\n",
    "        genome = create_genome(n)\n",
    "        if tuple(genome) in unique_set:\n",
    "            unique_set[tuple(genome)] = min(unique_set[tuple(genome)],stochastic_cost_function(genome))\n",
    "        else:\n",
    "            unique_set[tuple(genome)] = stochastic_cost_function(genome)\n",
    "    \n",
    "    heap = [(value,key) for key,value in unique_set.items()]\n",
    "    heapq.heapify(heap)\n",
    "    sorted_items = sorted(unique_set.items(), key=lambda x: x[1])\n",
    "    #Selecting q best solutions as nice centres \n",
    "    niche_centers = sorted_items[:q]\n",
    "    sol_space = sorted_items[q:]\n",
    "    centers = [center[0] for center in niche_centers]\n",
    "    clusters ={center:[] for center in centers}\n",
    "    for sol in sol_space:\n",
    "        clusters[tuple(closeset_centre(centers,sol[0]))].append(sol[0])\n",
    "    best_center =  centers[0]\n",
    "    sol_space = clusters[best_center]\n",
    "    #print('Cluster: ',clusters)\n",
    "    farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "    \n",
    "    for center in centers[1:]:\n",
    "        if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "            clusters[tuple(best_center)].append(center)\n",
    "            #print('cluster', clusters)\n",
    "            if len(clusters[center])  > 0:\n",
    "                clusters[tuple(best_center)].append(clusters.pop(center)[0])\n",
    "    centers_remaining = [list(key) for key in clusters.keys()][1:]\n",
    "    r = float('inf')\n",
    "    for center in centers_remaining:\n",
    "        r = min(euclidean_distance(center,best_center),r)\n",
    "    r = r//2\n",
    "    q = len(clusters.keys())\n",
    "    sol_vals_dict = {} # maps each solution to closest center\n",
    "\n",
    "   # print('clus: ',clusters)\n",
    "    for key, list_of_lists in clusters.items():\n",
    "       # print('lol: ',list_of_lists)\n",
    "        for lst in list_of_lists:\n",
    "           # print('lst: ',lst)\n",
    "            sol_vals_dict[tuple(lst)] = unique_set[tuple(lst)]\n",
    "\n",
    "    center_vals ={}\n",
    "    for center in clusters.keys():\n",
    "        center_vals[center] = stochastic_cost_function(center)\n",
    "    k +=1 \n",
    "    #print('ini ; ', k)\n",
    "    return clusters , q , r , sol_vals_dict , center_vals\n",
    "    \n",
    "    \n",
    "#clusters,q,r,sol_vals_dict,center_vals = initialize(4,200,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_pair_in_range(dictionary: Dict[Tuple[int], int], lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    eligible_pairs = [(key, value) for key, value in dictionary.items() \n",
    "                      if lower_bound <= value <= upper_bound]\n",
    "    #for key,value in dictionary.items():\n",
    "        #print(value)\n",
    "   # print('e[ :',eligible_pairs)\n",
    "    if not eligible_pairs:\n",
    "        return None  # No pairs found within the specified range\n",
    "    \n",
    "    return eligible_pairs[np.random.choice(len(eligible_pairs))][0]\n",
    "\n",
    "def get_mate(genome: List[int], sol_val_dict: Dict[Tuple[int], int]):\n",
    "    temp_dict = sol_val_dict.copy()  # Create a copy of the original dictionary\n",
    "    cost_value = temp_dict[tuple(genome)]  # Get the cost value for the genome\n",
    "    \n",
    "    del temp_dict[tuple(genome)]  # Remove the genome from the dictionary\n",
    "    \n",
    "    beta = 0.1\n",
    "    #print('sol_val: ',len(sol_val_dict))\n",
    "    mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "    #print('mate: ',mate)\n",
    "    counter= 0 \n",
    "    while not mate or list(mate) == genome:\n",
    "        if counter > 10:\n",
    "            mate = genome\n",
    "            break\n",
    "        #print('alppha: ',alpha)\n",
    "        #print('12312')\n",
    "        #Increasing visible space for finding mate\n",
    "        beta += 0.1\n",
    "        mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "        counter +=1\n",
    "    \n",
    "    return list(mate)\n",
    "\n",
    "def single_point_crossover(parent1, parent2):\n",
    "    size = len(parent1)\n",
    "    parent1 = tuple(parent1)\n",
    "    parent2 = tuple(parent2)\n",
    "    # Choose a random crossover point (excluding the first and last positions)\n",
    "    crossover_point = np.random.randint(1, size )\n",
    "    \n",
    "    # Create the first child\n",
    "    child1 = list(parent1[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer1 = crossover_point\n",
    "    for gene in parent2[crossover_point:] + parent2[:crossover_point]:\n",
    "        if gene not in child1:\n",
    "            child1[pointer1] = gene\n",
    "            pointer1 += 1\n",
    "            if pointer1 == size:\n",
    "                pointer1 = 0\n",
    "    \n",
    "    # Create the second child\n",
    "    child2 = list(parent2[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer2 = crossover_point\n",
    "    for gene in parent1[crossover_point:] + parent1[:crossover_point]:\n",
    "        if gene not in child2:\n",
    "            child2[pointer2] = gene\n",
    "            pointer2 += 1\n",
    "            if pointer2 == size:\n",
    "                pointer2 = 0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "def evolution(clusters,sol_vals_dict,center_vals_dict):\n",
    "    global k\n",
    "    centers = center_vals_dict.keys()\n",
    "    centers = [list(center) for center in centers]\n",
    "    center_vals = center_vals_dict.values()\n",
    "    center_vals = [val for val in center_vals]\n",
    "    while True:\n",
    "        sorted_items = sorted(sol_vals_dict.items(), key=lambda x: x[1])\n",
    "        #elite_genome = sorted_items[:5]\n",
    "        other_genomes = sorted_items\n",
    "        #elite_genomes = [temp[0] for temp in elite_genome]\n",
    "        other_genomes = [list(genome[0]) for genome in other_genomes]    \n",
    "            \n",
    "        \n",
    "        #print('pther_genomes: ',other_genomes)\n",
    "        #print('centers',centers)\n",
    "        m =len(other_genomes)\n",
    "        sol_val_new ={}\n",
    "        sol_space=[]\n",
    "        unique_set= set()\n",
    "        for _ in range(m):\n",
    "            #print('glob: ',k)\n",
    "\n",
    "            i =np.random.randint(0,m)\n",
    "            parent1 = other_genomes[i]\n",
    "            parent2 = get_mate(parent1,sol_vals_dict)\n",
    "            #print('qeqw')\n",
    "            child1,child2 = single_point_crossover(parent1,parent2)\n",
    "            cost_1 = stochastic_cost_function(child1)\n",
    "            cost_2 = stochastic_cost_function(child2)\n",
    "            add_1_to_sol = True\n",
    "            add_2_to_sol = True\n",
    "            unique_set.add(tuple(child1))\n",
    "            unique_set.add(tuple(child2))\n",
    "            #print('center_vals: ',center_vals)\n",
    "            for j in range(len(center_vals)):\n",
    "                if center_vals[j] > cost_1:\n",
    "                    add_1_to_sol = False\n",
    "                    centers[j] = child1\n",
    "                    center_vals[j] = cost_1\n",
    "                if center_vals[j] > cost_2:\n",
    "                    centers[j] = child2\n",
    "                    center_vals[j] = cost_2\n",
    "                    add_2_to_sol = False\n",
    "            if add_1_to_sol:\n",
    "                sol_val_new[tuple(child1)] = cost_1\n",
    "                sol_space.append(child1)\n",
    "            if add_2_to_sol:\n",
    "                sol_val_new[tuple(child2)] = cost_2\n",
    "                sol_space.append(child2)\n",
    "        centers1 = [tuple(center) for center in centers]\n",
    "       # print('center list:',centers1)\n",
    "        clusters ={center:[] for center in centers1}\n",
    "        for sol in sol_space:\n",
    "            #print('fwew',type(sol[0]))\n",
    "            #print('sol: ',sol)\n",
    "            clusters[tuple(closeset_centre(centers1,sol))].append(sol)\n",
    "        best_center =  centers1[0]\n",
    "        sol_space = clusters[best_center]\n",
    "        #print('Cluster: ',clusters)\n",
    "        #print(centers)\n",
    "        farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "        #print('sol_val:',sol_val_new)\n",
    "        for center in centers[1:]:\n",
    "            #print('eheh: ',center)\n",
    "            if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "                #print('center: ',best_center)\n",
    "                \n",
    "#                clusters[tuple(best_center)].append(center)\n",
    "                if tuple(center) in clusters:\n",
    "                    if len(clusters[tuple(center)]) >0:\n",
    "                        if tuple(center) in clusters:\n",
    "                            clusters[tuple(best_center)].append(clusters.pop(tuple(center))[0])\n",
    "        #print('Clusters: ',clusters)\n",
    "        k+=1\n",
    "        sol_vals_dict = sol_val_new\n",
    "        if len(centers) == 1:\n",
    "            print(\"Only one center is present\")\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            break\n",
    "        \n",
    "        if gas > GA_budget:\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            print('budget over')\n",
    "            break\n",
    "    return clusters\n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "#final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "#print(final_cluster_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"centers_items =  final_cluster_set.keys()\\ncenters = [list(i) for i in centers_items]\\nprint(centers)\\nsol_items = final_cluster_set.values()\\nfinal_clusters =[]\\n#print(sol_items)\\ncost_vals=[]\\nfor i,local_cluster in enumerate(sol_items):\\n    print(local_cluster)\\n    local_cluster=local_cluster[:2]\\n    local_cluster.append(centers[i])\\n    final_clusters.append(local_cluster)\\n    cost_vals.append(stochastic_cost_function(centers[i]))\\n    print('-'*20)\\n    print(final_clusters)\\nprint(final_clusters)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''centers_items =  final_cluster_set.keys()\n",
    "centers = [list(i) for i in centers_items]\n",
    "print(centers)\n",
    "sol_items = final_cluster_set.values()\n",
    "final_clusters =[]\n",
    "#print(sol_items)\n",
    "cost_vals=[]\n",
    "for i,local_cluster in enumerate(sol_items):\n",
    "    print(local_cluster)\n",
    "    local_cluster=local_cluster[:2]\n",
    "    local_cluster.append(centers[i])\n",
    "    final_clusters.append(local_cluster)\n",
    "    cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "    print('-'*20)\n",
    "    print(final_clusters)\n",
    "print(final_clusters)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fitness_vals=[]\\ntotal_costs = np.sum(cost_vals)\\nfor i in range(len(cost_vals)):\\n    fitness_vals.append(cost_vals[i]/total_costs)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fitness_vals=[]\n",
    "total_costs = np.sum(cost_vals)\n",
    "for i in range(len(cost_vals)):\n",
    "    fitness_vals.append(cost_vals[i]/total_costs)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPASS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import math\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise\n",
    "print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "def stochastic_cost_function(x:list[int],n:int):\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "        \n",
    "'''def get_n_neighbours(x: List[int], n: int, lower_bound: int = 0, upper_bound: int = 100) -> List[List[int]]:\n",
    "    neighbors = []\n",
    "    for _ in range(n):\n",
    "        mean = 0\n",
    "        std = 1\n",
    "        random_floats = mean + std * np.random.randn(len(x))\n",
    "        reach = np.round(random_floats).astype(int)\n",
    "        \n",
    "        # Create a new neighbor and ensure all values are within bounds\n",
    "        new_neighbor = []\n",
    "        for i, val in enumerate(x):\n",
    "            new_val = val + reach[i]\n",
    "            new_val = max(lower_bound, min(new_val, upper_bound))  # Clamp value between lower and upper bounds\n",
    "            new_neighbor.append(new_val)\n",
    "        \n",
    "        neighbors.append(new_neighbor)\n",
    "    \n",
    "    return neighbors'''\n",
    "\n",
    "\n",
    "#get_n_neighbours([10,10],8)\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "def euclidean_distance(list1: List[int], list2: List[int]) -> float:\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same length\")\n",
    "    \n",
    "    sum_squared_diff = sum((a - b) ** 2 for a, b in zip(list1, list2))\n",
    "    distance = math.sqrt(sum_squared_diff)\n",
    "    return distance\n",
    "from heapq import nsmallest\n",
    "\n",
    "def find_closest_keys(x_star_k: List[int], V_k: Dict[Tuple[int, ...], float], n: int = 10) -> List[Tuple[int, ...]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k.keys() \n",
    "        if key != x_star_k_tuple\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key, _ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: Dict[Tuple[int,...], float]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k.keys()) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(x_star_k, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "def check_redundancy(x_star_k : List[int], V_k:List[List[int]]):\n",
    "    x_star_k = np.array(x_star_k)\n",
    "    redundancy_status = []\n",
    "    \n",
    "    for x_i in V_k:\n",
    "        x_i = np.array(x_i)\n",
    "        model = gp.Model()\n",
    "        model.setParam('OutputFlag', 0)\n",
    "        #print('x_star: ',x_star_k)\n",
    "        n = len(x_star_k)\n",
    "        x = model.addMVar(shape=n, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "        \n",
    "        midpoint_i = (x_star_k + x_i) / 2\n",
    "        diff = x_star_k - x_i\n",
    "        \n",
    "        # Correct way to create the objective function\n",
    "        objective = gp.LinExpr()\n",
    "        for j in range(n):\n",
    "            #print('j:,',j,diff)\n",
    "            objective += diff[j] * (x[j] - midpoint_i[j])\n",
    "        model.setObjective(objective, GRB.MINIMIZE)\n",
    "        \n",
    "        for x_j in V_k:\n",
    "            if not np.array_equal(np.array(x_j), x_i):\n",
    "                x_j = np.array(x_j)\n",
    "                midpoint_j = (x_star_k + x_j) / 2\n",
    "                # Correct way to create the constraint\n",
    "                constraint = gp.LinExpr()\n",
    "                for j in range(n):\n",
    "                    #print('j: ',j)\n",
    "                    constraint += (x_star_k[j] - x_j[j]) * (x[j] - midpoint_j[j])\n",
    "                model.addConstr(constraint >= 0)\n",
    "        \n",
    "        model.optimize()\n",
    "        \n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            obj_value = model.ObjVal\n",
    "            redundancy_status.append(obj_value >= 0)\n",
    "        else:\n",
    "            redundancy_status.append(False)\n",
    "    \n",
    "    return redundancy_status\n",
    "from multiprocessing import heap\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def find_closest_keys(x_star_k: List[int], V_k: List[List[int]], n: int = 10) -> List[List[int]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    #x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k \n",
    "        if key != x_star_k\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key,_ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: List[List[int]]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(x_star_k, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "\n",
    "import random\n",
    "\n",
    "def randomly_sample_solution(population: List[List[int]],ml:int):\n",
    "    ml = min(ml,len(population))\n",
    "    return random.sample(population,ml)\n",
    "\n",
    "    \n",
    "global global_store\n",
    "global global_reps\n",
    "global_store={}\n",
    "global_reps ={}\n",
    "\n",
    "def simulate(population: List[List[int]],budget): # here population refers to the niche being explored\n",
    "    temp_heap=[]\n",
    "    global gas\n",
    "    gas = 0\n",
    "    k=2\n",
    "    #global global_store\n",
    "    \n",
    "    for i in population:\n",
    "        temp_heap.append((stochastic_cost_function(i,10),i))\n",
    "        \n",
    "    for i in temp_heap:\n",
    "        solution = tuple(i[1])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], i[0])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = i[0]\n",
    "            global_reps[solution] = 1\n",
    "        \n",
    "    heapq.heapify(temp_heap)\n",
    "    x_star_k_temp= heapq.heappop(temp_heap)\n",
    "    x_star_k = x_star_k_temp[1]\n",
    "    x_star_k_val = x_star_k_temp[0]\n",
    "    heap=[x_star_k_temp]\n",
    "    heapq.heapify(heap)\n",
    "    V_k = population\n",
    "    population.remove(x_star_k)\n",
    "    if len(population) >0:\n",
    "        for sol in population:\n",
    "            #bound = ((10**20)**(1/len(sol)))/2\n",
    "            #bound = ((10**20)**(1/4))/2 \n",
    "            #if k ==2:\n",
    "                #print('bound +-: ',bound)\n",
    "                \n",
    "            mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k) #most promising area\n",
    "            while(len(mp_area)<1):\n",
    "                mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k)\n",
    "            mp_area_vals=[ stochastic_cost_function(sol) for i in mp_area]\n",
    "            #gas += SAR(k) * len(mp_area_vals)\n",
    "            \n",
    "     \n",
    "        #print('first mp area: ',mp_area)\n",
    "    else:\n",
    "        #bound = ((10**20)**(1/len(sol)))/2\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        mp_area_vals=[ stochastic_cost_function(x_star_k) for i in mp_area]\n",
    "    for i in range(len(mp_area)):\n",
    "        solution = tuple(mp_area[i])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], mp_area_vals[i])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = mp_area_vals[i]\n",
    "            global_reps[solution] = 1\n",
    "    running = True\n",
    "    xk_store=[]\n",
    "    while running:\n",
    "        V_k += randomly_sample_solution(mp_area,100)\n",
    "        temp =[]\n",
    "        for i in range(len(V_k)):\n",
    "            temp.append((stochastic_cost_function(V_k[i]),V_k[i]))\n",
    "           # gas += SAR(k)\n",
    "       # print('V_k before prunning: ',V_k)\n",
    "        for i in temp:\n",
    "            solution = tuple(i[1])\n",
    "            if solution in global_store:\n",
    "                global_store[solution] = min(global_store[solution], i[0])\n",
    "                global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "            else:\n",
    "                global_store[solution] = i[0]\n",
    "                global_reps[solution] = 1\n",
    "        heapq.heapify(temp)\n",
    "        x_star_k_temp = heapq.heappop(temp)\n",
    "        x_star_k_val = x_star_k_temp[0]\n",
    "        x_star_k = x_star_k_temp[1]\n",
    "        V_k_temp = V_k.copy()\n",
    "        V_k_temp.remove(x_star_k)\n",
    "        redundant_variable = check_redundancy(x_star_k,V_k_temp)\n",
    "        V_k=[x_star_k]\n",
    "        for i in range(len(redundant_variable)):\n",
    "            if redundant_variable[i]:\n",
    "                V_k.append(V_k_temp[i])\n",
    "       # print('V_k post prunning: ',V_k)\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        mp_area_with_vals = [(mp_area[i],stochastic_cost_function(mp_area[i],10)) for i in range(len(mp_area))]\n",
    "        #print('mp area: ',mp_area_with_vals)\n",
    "        k+=1\n",
    "        #print('com : ', k)\n",
    "        count = 0\n",
    "        while len(mp_area) == 0 and count <=10:\n",
    "            #print('hehe: ',mp_area)\n",
    "            mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "            count +=1\n",
    "        if len(mp_area) ==1 :\n",
    "            running = False\n",
    "        if gas >budget:\n",
    "            print('Budget Over')\n",
    "            running = False\n",
    "        xk_store.append(x_star_k_val)\n",
    "        #print('lol')\n",
    "    return (x_star_k,x_star_k_val)#,xk_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGA TO COMPASS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outputs =[]\\nfor i,cluster in enumerate(final_clusters):\\n    continue\\n    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Outputs =[]\n",
    "for i,cluster in enumerate(final_clusters):\n",
    "    continue\n",
    "    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISC(total_budget,alpha,no_of_clusters=no_of_clusters):\n",
    "    #no_of_clusters = 3\n",
    "    clusters,q,r,sol_vals_dict,center_vals = initialize(10,no_of_clusters)\n",
    "    #print('ini')\n",
    "    final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "    #print('evo')\n",
    "    centers_items =  final_cluster_set.keys()\n",
    "    centers = [list(i) for i in centers_items]\n",
    "    #print(centers)\n",
    "    sol_items = final_cluster_set.values()\n",
    "    final_clusters =[]\n",
    "    #print(sol_items)\n",
    "    cost_vals=[]\n",
    "    assign_budgets(total_budget,alpha=alpha)\n",
    "    for i,local_cluster in enumerate(sol_items):\n",
    "        #print(local_cluster)\n",
    "        local_cluster=local_cluster[:2]\n",
    "        local_cluster.append(centers[i])\n",
    "        final_clusters.append(local_cluster)\n",
    "        cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "        #print('-'*20)\n",
    "        #print(final_clusters)\n",
    "    #print(final_clusters)\n",
    "    fitness_vals=[]\n",
    "    total_costs = np.sum(cost_vals)\n",
    "    for i in range(len(cost_vals)):\n",
    "        fitness_vals.append(cost_vals[i]/total_costs)\n",
    "    Outputs =[]\n",
    "    for i,cluster in enumerate(final_clusters):\n",
    "        \n",
    "        Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))\n",
    "    sorted_outputs = sorted(Outputs,key= lambda x:x[1])\n",
    "   # print(sorted_outputs[0])\n",
    "    return sorted_outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_ga_compass = 0.3, cluster_count = 3\n",
      "budget over\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Budget Over\n",
      "budget over\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m best_configuration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     configuration, performance \u001b[38;5;241m=\u001b[39m ISC(total_budget, ratio, clusters)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m performance \u001b[38;5;241m<\u001b[39m best_value:\n\u001b[1;32m     16\u001b[0m         best_value \u001b[38;5;241m=\u001b[39m performance\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mISC\u001b[0;34m(total_budget, alpha, no_of_clusters)\u001b[0m\n\u001b[1;32m     28\u001b[0m  Outputs \u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     29\u001b[0m  \u001b[38;5;28;01mfor\u001b[39;00m i,cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(final_clusters):\n\u001b[0;32m---> 31\u001b[0m      Outputs\u001b[38;5;241m.\u001b[39mappend(simulate(cluster,compass_budget\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mfitness_vals[i])))\n\u001b[1;32m     32\u001b[0m  sorted_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(Outputs,key\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(sorted_outputs[0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 254\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(population, budget)\u001b[0m\n\u001b[1;32m    252\u001b[0m V_k_temp \u001b[38;5;241m=\u001b[39m V_k\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    253\u001b[0m V_k_temp\u001b[38;5;241m.\u001b[39mremove(x_star_k)\n\u001b[0;32m--> 254\u001b[0m redundant_variable \u001b[38;5;241m=\u001b[39m check_redundancy(x_star_k,V_k_temp)\n\u001b[1;32m    255\u001b[0m V_k\u001b[38;5;241m=\u001b[39m[x_star_k]\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(redundant_variable)):\n",
      "Cell \u001b[0;32mIn[11], line 118\u001b[0m, in \u001b[0;36mcheck_redundancy\u001b[0;34m(x_star_k, V_k)\u001b[0m\n\u001b[1;32m    115\u001b[0m         constraint \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mLinExpr()\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;66;03m#print('j: ',j)\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m             constraint \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (x_star_k[j] \u001b[38;5;241m-\u001b[39m x_j[j]) \u001b[38;5;241m*\u001b[39m (x[j] \u001b[38;5;241m-\u001b[39m midpoint_j[j])\n\u001b[1;32m    119\u001b[0m         model\u001b[38;5;241m.\u001b[39maddConstr(constraint \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    121\u001b[0m model\u001b[38;5;241m.\u001b[39moptimize()\n",
      "File \u001b[0;32msrc/gurobipy/mvar.pxi:363\u001b[0m, in \u001b[0;36mgurobipy.MVar.__sub__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/mvar.pxi:415\u001b[0m, in \u001b[0;36mgurobipy.MVar._toexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/mlinexpr.pxi:519\u001b[0m, in \u001b[0;36mgurobipy.MLinExpr._from_mvar\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/mlinexpr.pxi:541\u001b[0m, in \u001b[0;36mgurobipy.MLinExpr._from_mvar_compact\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/mlinexpr.pxi:256\u001b[0m, in \u001b[0;36mgurobipy.MLinExpr._from_compact_affine_expr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/btp/lib/python3.12/site-packages/scipy/sparse/_compressed.py:93\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSC arrays don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg1\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input. Use 2D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m     coo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coo_container(arg1, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 93\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m coo\u001b[38;5;241m.\u001b[39m_coo_to_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m arrays\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Read matrix dimensions given, if any\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/btp/lib/python3.12/site-packages/scipy/sparse/_coo.py:358\u001b[0m, in \u001b[0;36m_coo_base._coo_to_compressed\u001b[0;34m(self, swap)\u001b[0m\n\u001b[1;32m    355\u001b[0m nnz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(major)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# convert idx_dtype intc to int32 for pythran.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# tested in scipy/optimize/tests/test__numdiff.py::test_group_columns\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords, maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, N))\n\u001b[1;32m    359\u001b[0m major \u001b[38;5;241m=\u001b[39m major\u001b[38;5;241m.\u001b[39mastype(idx_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    360\u001b[0m minor \u001b[38;5;241m=\u001b[39m minor\u001b[38;5;241m.\u001b[39mastype(idx_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/btp/lib/python3.12/site-packages/scipy/sparse/_base.py:1349\u001b[0m, in \u001b[0;36m_spbase._get_index_dtype\u001b[0;34m(self, arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index_dtype\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;66;03m# Don't check contents for array API\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_index_dtype(arrays,\n\u001b[1;32m   1350\u001b[0m                        maxval,\n\u001b[1;32m   1351\u001b[0m                        (check_contents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, sparray)))\n",
      "File \u001b[0;32m~/miniconda3/envs/btp/lib/python3.12/site-packages/scipy/sparse/_sputils.py:172\u001b[0m, in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mBased on input (integer) arrays `a`, determine a suitable index data\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mtype that can hold the data in the arrays.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m int32min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmin)\n\u001b[0;32m--> 172\u001b[0m int32max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# not using intc directly due to misinteractions with pythran\u001b[39;00m\n\u001b[1;32m    175\u001b[0m dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32 \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mintc()\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mint64\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clustering_outcomes = []\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over ratio_ga_compass and cluster_count values\n",
    "for ratio in np.arange(0.3, 0.7, 0.1):  # Include 1.0 in the range\n",
    "    for clusters in range(3, 6):  # cluster_count values from 1 to 5\n",
    "        print(f'ratio_ga_compass = {ratio:.1f}, cluster_count = {clusters}')\n",
    "        \n",
    "        # Run improved_stochastic_clustering 4 times and keep the minimum\n",
    "        best_value = float('inf')\n",
    "        best_configuration = None\n",
    "        for _ in range(4):\n",
    "            configuration, performance = ISC(total_budget, ratio, clusters)\n",
    "            if performance < best_value:\n",
    "                best_value = performance\n",
    "                best_configuration = configuration\n",
    "        \n",
    "        clustering_outcomes.append((ratio, clusters, best_value))\n",
    "        print(f'Best performance after 4 runs: {best_value}')\n",
    "        # Define the variables you want to keep\n",
    "        \n",
    "# Convert clustering_outcomes to a numpy array for easier manipulation\n",
    "outcome_array = np.array(clustering_outcomes)\n",
    "\n",
    "# Create a plot for each ratio value\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o')\n",
    "    \n",
    "    plt.title(f'Best Performance for Ratio={ratio:.1f} (4 runs each)')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Best Performance Value')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(f'performance_ratio_{ratio:.1f}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create a single plot with all ratio values\n",
    "plt.figure(figsize=(12, 8))\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o', label=f'Ratio={ratio:.1f}')\n",
    "\n",
    "plt.title('Best Performance for Different Ratios and Cluster Counts (4 runs each)')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Best Performance Value')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
