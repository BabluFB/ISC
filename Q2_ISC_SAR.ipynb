{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hehe\n"
     ]
    }
   ],
   "source": [
    "print('hehe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\nimport numpy as np\\nimport time\\nimport math \\n\\ndef create_route(customer_nodes):\\n    route = customer_nodes[:]\\n    random.shuffle(route)\\n    return route\\n\\ndef get_n_neighbours(x, n, lower_bound, upper_bound):\\n    neighbors = set()\\n    while len(neighbors) < n:\\n        i, j = random.sample(range(len(x)), 2)\\n        neighbor = x.copy()\\n        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\\n        neighbors.add(tuple(neighbor)) \\n    return [list(neighbor) for neighbor in neighbors]\\n\\ndef create_multiple_routes(customer_nodes, n):\\n    routes = []\\n    unique_routes = set()\\n    \\n    while len(routes) < n:\\n        new_route = create_route(customer_nodes)\\n        route_tuple = tuple(new_route)\\n        \\n        if route_tuple not in unique_routes:\\n            unique_routes.add(route_tuple)\\n            routes.append(new_route)\\n    \\n    return routes\\n\\ndef generate_cost_matrix(num_nodes, num_customers, seed=None):\\n    if seed is not None:\\n        np.random.seed(seed)\\n        random.seed(seed)\\n\\n    grid_rows = num_customers#int(np.sqrt(num_nodes))\\n    grid_cols = grid_rows\\n    grid = np.arange(num_customers**2).reshape(grid_rows, grid_cols)\\n\\n    node_list = list(range(1, num_nodes))  # Exclude 0 as it\\'s the depot\\n\\n    def gen_node_list(node_list, num_customers):\\n        return random.sample(node_list, min(num_customers, len(node_list)))\\n\\n    customer_node_list = gen_node_list(node_list, num_customers)\\n\\n    def distcalc(customer_node_list):\\n        nodecoords = []\\n        nodecoords.append([0, 0])  # Starting point (depot)\\n        for node in customer_node_list:\\n            a, b = np.where(grid == node)\\n            nodecoords.append([a[0], b[0]])\\n\\n        distmat = np.zeros((len(nodecoords), len(nodecoords)))\\n        for i in range(len(nodecoords)):\\n            for j in range(len(nodecoords)):\\n                distmat[i, j] = abs(nodecoords[i][0] - nodecoords[j][0]) * 5 + abs(nodecoords[i][1] - nodecoords[j][1]) * 5\\n\\n        return distmat, customer_node_list\\n\\n    cost_matrix, customer_node_list = distcalc(customer_node_list)\\n\\n    return cost_matrix, customer_node_list\\n\\n# Generate the cost matrix and customer node list with a specific seed\\nCost_matrix, Customer_nodes = generate_cost_matrix(60, 10, seed=1234)\\nprint(\"Customer Nodes:\", Customer_nodes)\\nprint(\"Cost Matrix:\")\\nprint(Cost_matrix)\\n\\ndef SAR(k):\\n    n0=8\\n    return math.ceil(n0*(np.log(k)**2))\\nk = 2\\ndef stoichastic_cost_helper(route, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=None):\\n    if seed is not None:\\n        np.random.seed(seed)\\n\\n    total_cost = 0.0\\n    n = len(route)\\n    total_cost += cost_matrix[0][customer_nodes.index(route[0])] # depot to first customer\\n    for i in range(n):\\n        current_city = route[i]\\n        next_city = route[(i + 1) % n]\\n\\n        current_index = customer_nodes.index(current_city)\\n        next_index = customer_nodes.index(next_city)\\n\\n        original_cost = cost_matrix[current_index + 1][next_index + 1]  # +1 because 0 is depot\\n\\n        error_range = original_cost * (percentage / 100)\\n        new_cost = np.random.uniform(original_cost - error_range, original_cost + error_range)\\n        \\n        total_cost += new_cost\\n\\n    return total_cost\\n\\ndef stochastic_cost_function(route,n, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=42):\\n    global gas , k\\n    n = 7#SAR(k)\\n    gas += n#SAR(n)\\n    #print(gas)\\n    return np.mean([stoichastic_cost_helper(route, cost_matrix, customer_nodes, seed=seed) for _ in range(n)])\\n\\n# Initialize gas variable\\ngas = 0\\n\\n# Create an initial solution (route)\\ninitial_sol = Customer_nodes  # Use the generated customer nodes\\nprint(\"Initial Route:\", initial_sol)\\n\\n# Calculate the stochastic cost\\nstochastic_cost_value = stochastic_cost_function(initial_sol,n=SAR(k), cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, seed=42)\\nprint(\"Stochastic Cost:\", stochastic_cost_value)\\nprint(\"Gas used:\", gas)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math \n",
    "\n",
    "def create_route(customer_nodes):\n",
    "    route = customer_nodes[:]\n",
    "    random.shuffle(route)\n",
    "    return route\n",
    "\n",
    "def get_n_neighbours(x, n, lower_bound, upper_bound):\n",
    "    neighbors = set()\n",
    "    while len(neighbors) < n:\n",
    "        i, j = random.sample(range(len(x)), 2)\n",
    "        neighbor = x.copy()\n",
    "        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]\n",
    "        neighbors.add(tuple(neighbor)) \n",
    "    return [list(neighbor) for neighbor in neighbors]\n",
    "\n",
    "def create_multiple_routes(customer_nodes, n):\n",
    "    routes = []\n",
    "    unique_routes = set()\n",
    "    \n",
    "    while len(routes) < n:\n",
    "        new_route = create_route(customer_nodes)\n",
    "        route_tuple = tuple(new_route)\n",
    "        \n",
    "        if route_tuple not in unique_routes:\n",
    "            unique_routes.add(route_tuple)\n",
    "            routes.append(new_route)\n",
    "    \n",
    "    return routes\n",
    "\n",
    "def generate_cost_matrix(num_nodes, num_customers, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    grid_rows = num_customers#int(np.sqrt(num_nodes))\n",
    "    grid_cols = grid_rows\n",
    "    grid = np.arange(num_customers**2).reshape(grid_rows, grid_cols)\n",
    "\n",
    "    node_list = list(range(1, num_nodes))  # Exclude 0 as it's the depot\n",
    "\n",
    "    def gen_node_list(node_list, num_customers):\n",
    "        return random.sample(node_list, min(num_customers, len(node_list)))\n",
    "\n",
    "    customer_node_list = gen_node_list(node_list, num_customers)\n",
    "\n",
    "    def distcalc(customer_node_list):\n",
    "        nodecoords = []\n",
    "        nodecoords.append([0, 0])  # Starting point (depot)\n",
    "        for node in customer_node_list:\n",
    "            a, b = np.where(grid == node)\n",
    "            nodecoords.append([a[0], b[0]])\n",
    "\n",
    "        distmat = np.zeros((len(nodecoords), len(nodecoords)))\n",
    "        for i in range(len(nodecoords)):\n",
    "            for j in range(len(nodecoords)):\n",
    "                distmat[i, j] = abs(nodecoords[i][0] - nodecoords[j][0]) * 5 + abs(nodecoords[i][1] - nodecoords[j][1]) * 5\n",
    "\n",
    "        return distmat, customer_node_list\n",
    "\n",
    "    cost_matrix, customer_node_list = distcalc(customer_node_list)\n",
    "\n",
    "    return cost_matrix, customer_node_list\n",
    "\n",
    "# Generate the cost matrix and customer node list with a specific seed\n",
    "Cost_matrix, Customer_nodes = generate_cost_matrix(60, 10, seed=1234)\n",
    "print(\"Customer Nodes:\", Customer_nodes)\n",
    "print(\"Cost Matrix:\")\n",
    "print(Cost_matrix)\n",
    "\n",
    "def SAR(k):\n",
    "    n0=8\n",
    "    return math.ceil(n0*(np.log(k)**2))\n",
    "k = 2\n",
    "def stoichastic_cost_helper(route, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    total_cost = 0.0\n",
    "    n = len(route)\n",
    "    total_cost += cost_matrix[0][customer_nodes.index(route[0])] # depot to first customer\n",
    "    for i in range(n):\n",
    "        current_city = route[i]\n",
    "        next_city = route[(i + 1) % n]\n",
    "\n",
    "        current_index = customer_nodes.index(current_city)\n",
    "        next_index = customer_nodes.index(next_city)\n",
    "\n",
    "        original_cost = cost_matrix[current_index + 1][next_index + 1]  # +1 because 0 is depot\n",
    "\n",
    "        error_range = original_cost * (percentage / 100)\n",
    "        new_cost = np.random.uniform(original_cost - error_range, original_cost + error_range)\n",
    "        \n",
    "        total_cost += new_cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def stochastic_cost_function(route,n, cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, percentage=10, seed=42):\n",
    "    global gas , k\n",
    "    n = 7#SAR(k)\n",
    "    gas += n#SAR(n)\n",
    "    #print(gas)\n",
    "    return np.mean([stoichastic_cost_helper(route, cost_matrix, customer_nodes, seed=seed) for _ in range(n)])\n",
    "\n",
    "# Initialize gas variable\n",
    "gas = 0\n",
    "\n",
    "# Create an initial solution (route)\n",
    "initial_sol = Customer_nodes  # Use the generated customer nodes\n",
    "print(\"Initial Route:\", initial_sol)\n",
    "\n",
    "# Calculate the stochastic cost\n",
    "stochastic_cost_value = stochastic_cost_function(initial_sol,n=SAR(k), cost_matrix=Cost_matrix, customer_nodes=Customer_nodes, seed=42)\n",
    "print(\"Stochastic Cost:\", stochastic_cost_value)\n",
    "print(\"Gas used:\", gas)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER DEFINED VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound = -100\n",
    "up_bound = 100\n",
    "no_of_clusters =4\n",
    "solution_dimension = 4\n",
    "total_budget = 2e4\n",
    "alpha = 0.3\n",
    "no_of_neighbours = 30\n",
    "step_size_param = 10\n",
    "step_size = step_size_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22, 1], [-6, 38], [5, 1], [9, 17], [5, 3], [8, 8], [6, 3], [25, 20]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import math\n",
    "def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise\n",
    "def stochastic_cost_function(x:list[int],n:int = 10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])\n",
    "\n",
    "\n",
    "def get_n_neighbours(x: list[int], n: int = no_of_neighbours, lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    neighbors = []\n",
    "    global step_size\n",
    "    for i in range(n):\n",
    "        reach =0 + step_sizw * np.random.randn(1, len(x))  # normal distribution with 0 mean and 5 std\n",
    "        new_neighbor = np.clip(np.array(x) + reach[0], lower_bound, upper_bound)\n",
    "        new_neighbor = np.round(new_neighbor).astype(int)\n",
    "        neighbors.append(list(new_neighbor))\n",
    "    return neighbors\n",
    "k = 2\n",
    "def SAR(k):\n",
    "    \n",
    "    n0=8\n",
    "    return math.ceil(n0*(np.log(k)**2))\n",
    "get_n_neighbours([10,10],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_budget = 1e4\n",
    "GA_budget = 0\n",
    "compass_budget = 0\n",
    "def assign_budgets(total_budget,alpha =alpha):\n",
    "    global GA_budget , compass_budget\n",
    "    #alpha = 0.5\n",
    "    GA_budget = total_budget*alpha\n",
    "    compass_budget = total_budget*(1-alpha)\n",
    "assign_budgets(total_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, -3, -79, -43]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import heapq, random\n",
    "#global gas \n",
    "gas = 0\n",
    "def create_genome(n,lower_bound =low_bound,upper_bound=up_bound):\n",
    "    return [random.randint(lower_bound, upper_bound) for _ in range(n)]\n",
    "    #return [np.random.randint(lower_bound,upper_bound) for _ in range(n)]\n",
    "print(create_genome(4))\n",
    "\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise'''\n",
    "#print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "'''def stochastic_cost_function(x:list[int],n:int=10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "\n",
    "def euclidean_distance(centre_1 : List[int],centre_2: List[int]):\n",
    "    array1 = np.array(centre_1)\n",
    "    array2 = np.array(centre_2)\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(array1 - array2)\n",
    "    return euclidean_distance\n",
    "\n",
    "def find_farthest_point(center: List[int], sol_space: List[List[int]]) -> Tuple[List[int], float]: #Finds the farthest point in the solution space from the centre\n",
    "    max_distance = 0\n",
    "    farthest_point = None\n",
    "    \n",
    "    for point in sol_space:\n",
    "        # Calculate the squared distance\n",
    "        squared_distance = sum((c - p)**2 for c, p in zip(center, point))\n",
    "        \n",
    "        if squared_distance > max_distance:\n",
    "            max_distance = squared_distance\n",
    "            farthest_point = point\n",
    "    \n",
    "    # Calculate the actual distance (square root of the squared distance)\n",
    "    max_distance = np.sqrt(max_distance)\n",
    "    \n",
    "    return farthest_point, max_distance\n",
    "\n",
    "def closeset_centre(centers:List[List[int]],visited_solution:List[int]) -> List[int]:#Finds the closests centre to the point\n",
    "    closest = [float('inf') for _ in centers]\n",
    "    min_dist= float('inf')\n",
    "    for center in centers:\n",
    "        dist =euclidean_distance(center,visited_solution)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = center\n",
    "        #print('hehe: ',closest)\n",
    "    return closest\n",
    "#INITIALIZATION STEP\n",
    "def initialize(mg:int,q:int = no_of_clusters,n:int = solution_dimension) : #n is dimension of solution vector and mg is number of solns sampled\n",
    "    #n=4\n",
    "    global gas,k , low_bound, up_bound\n",
    "    unique_set = {}\n",
    "    while len(unique_set) <mg: # Sampling Mg Solutions from the feasible set\n",
    "        temp_lower_bound = int((low_bound*3/4) + (up_bound*1/4)) \n",
    "        temp_upper_bound = int(low_bound*1/4 + up_bound*3/4) \n",
    "        #print('sadas',temp_lower_bound,temp_upper_bound)\n",
    "        genome = create_genome(n,temp_lower_bound,temp_upper_bound)\n",
    "        if tuple(genome) in unique_set:\n",
    "            unique_set[tuple(genome)] = min(unique_set[tuple(genome)],stochastic_cost_function(genome))\n",
    "        else:\n",
    "            unique_set[tuple(genome)] = stochastic_cost_function(genome)\n",
    "    \n",
    "    heap = [(value,key) for key,value in unique_set.items()]\n",
    "    heapq.heapify(heap)\n",
    "    sorted_items = sorted(unique_set.items(), key=lambda x: x[1])\n",
    "    #Selecting q best solutions as nice centres \n",
    "    niche_centers = sorted_items[:q]\n",
    "    sol_space = sorted_items[q:]\n",
    "    centers = [center[0] for center in niche_centers]\n",
    "    clusters ={center:[] for center in centers}\n",
    "    for sol in sol_space:\n",
    "        clusters[tuple(closeset_centre(centers,sol[0]))].append(sol[0])\n",
    "    best_center =  centers[0]\n",
    "    sol_space = clusters[best_center]\n",
    "    #print('Cluster: ',clusters)\n",
    "    farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "    \n",
    "    for center in centers[1:]:\n",
    "        if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "            clusters[tuple(best_center)].append(center)\n",
    "            #print('cluster', clusters)\n",
    "            if len(clusters[center])  > 0:\n",
    "                clusters[tuple(best_center)].append(clusters.pop(center)[0])\n",
    "    centers_remaining = [list(key) for key in clusters.keys()][1:]\n",
    "    r = float('inf')\n",
    "    for center in centers_remaining:\n",
    "        r = min(euclidean_distance(center,best_center),r)\n",
    "    r = r//2\n",
    "    q = len(clusters.keys())\n",
    "    sol_vals_dict = {} # maps each solution to closest center\n",
    "\n",
    "   # print('clus: ',clusters)\n",
    "    for key, list_of_lists in clusters.items():\n",
    "       # print('lol: ',list_of_lists)\n",
    "        for lst in list_of_lists:\n",
    "           # print('lst: ',lst)\n",
    "            sol_vals_dict[tuple(lst)] = unique_set[tuple(lst)]\n",
    "\n",
    "    center_vals ={}\n",
    "    for center in clusters.keys():\n",
    "        center_vals[center] = stochastic_cost_function(center)\n",
    "    k +=1 \n",
    "    #print('ini ; ', k)\n",
    "    return clusters , q , r , sol_vals_dict , center_vals\n",
    "    \n",
    "    \n",
    "#clusters,q,r,sol_vals_dict,center_vals = initialize(4,200,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_pair_in_range(dictionary: Dict[Tuple[int], int], lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    eligible_pairs = [(key, value) for key, value in dictionary.items() \n",
    "                      if lower_bound <= value <= upper_bound]\n",
    "    #for key,value in dictionary.items():\n",
    "        #print(value)\n",
    "   # print('e[ :',eligible_pairs)\n",
    "    if not eligible_pairs:\n",
    "        return None  # No pairs found within the specified range\n",
    "    \n",
    "    return eligible_pairs[np.random.choice(len(eligible_pairs))][0]\n",
    "\n",
    "def get_mate(genome: List[int], sol_val_dict: Dict[Tuple[int], int]):\n",
    "    temp_dict = sol_val_dict.copy()  # Create a copy of the original dictionary\n",
    "    cost_value = temp_dict[tuple(genome)]  # Get the cost value for the genome\n",
    "    \n",
    "    del temp_dict[tuple(genome)]  # Remove the genome from the dictionary\n",
    "    \n",
    "    beta = 0.1\n",
    "    #print('sol_val: ',len(sol_val_dict))\n",
    "    mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "    #print('mate: ',mate)\n",
    "    counter= 0 \n",
    "    while not mate or list(mate) == genome:\n",
    "        if counter > 10:\n",
    "            mate = genome\n",
    "            break\n",
    "        #print('alppha: ',alpha)\n",
    "        #print('12312')\n",
    "        #Increasing visible space for finding mate\n",
    "        beta += 0.1\n",
    "        mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "        counter +=1\n",
    "    \n",
    "    return list(mate)\n",
    "\n",
    "def single_point_crossover(parent1, parent2):\n",
    "    size = len(parent1)\n",
    "    parent1 = tuple(parent1)\n",
    "    parent2 = tuple(parent2)\n",
    "    # Choose a random crossover point (excluding the first and last positions)\n",
    "    crossover_point = np.random.randint(1, size )\n",
    "    \n",
    "    # Create the first child\n",
    "    child1 = list(parent1[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer1 = crossover_point\n",
    "    for gene in parent2[crossover_point:] + parent2[:crossover_point]:\n",
    "        if gene not in child1:\n",
    "            child1[pointer1] = gene\n",
    "            pointer1 += 1\n",
    "            if pointer1 == size:\n",
    "                pointer1 = 0\n",
    "    \n",
    "    # Create the second child\n",
    "    child2 = list(parent2[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer2 = crossover_point\n",
    "    for gene in parent1[crossover_point:] + parent1[:crossover_point]:\n",
    "        if gene not in child2:\n",
    "            child2[pointer2] = gene\n",
    "            pointer2 += 1\n",
    "            if pointer2 == size:\n",
    "                pointer2 = 0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "def evolution(clusters,sol_vals_dict,center_vals_dict):\n",
    "    global k\n",
    "    centers = center_vals_dict.keys()\n",
    "    centers = [list(center) for center in centers]\n",
    "    center_vals = center_vals_dict.values()\n",
    "    center_vals = [val for val in center_vals]\n",
    "    while True:\n",
    "        sorted_items = sorted(sol_vals_dict.items(), key=lambda x: x[1])\n",
    "        #elite_genome = sorted_items[:5]\n",
    "        other_genomes = sorted_items\n",
    "        #elite_genomes = [temp[0] for temp in elite_genome]\n",
    "        other_genomes = [list(genome[0]) for genome in other_genomes]    \n",
    "            \n",
    "        \n",
    "        #print('pther_genomes: ',other_genomes)\n",
    "        #print('centers',centers)\n",
    "        m =len(other_genomes)\n",
    "        sol_val_new ={}\n",
    "        sol_space=[]\n",
    "        unique_set= set()\n",
    "        for _ in range(m):\n",
    "            #print('glob: ',k)\n",
    "\n",
    "            i =np.random.randint(0,m)\n",
    "            parent1 = other_genomes[i]\n",
    "            parent2 = get_mate(parent1,sol_vals_dict)\n",
    "            #print('qeqw')\n",
    "            child1,child2 = single_point_crossover(parent1,parent2)\n",
    "            cost_1 = stochastic_cost_function(child1)\n",
    "            cost_2 = stochastic_cost_function(child2)\n",
    "            add_1_to_sol = True\n",
    "            add_2_to_sol = True\n",
    "            unique_set.add(tuple(child1))\n",
    "            unique_set.add(tuple(child2))\n",
    "            #print('center_vals: ',center_vals)\n",
    "            for j in range(len(center_vals)):\n",
    "                if center_vals[j] > cost_1:\n",
    "                    add_1_to_sol = False\n",
    "                    centers[j] = child1\n",
    "                    center_vals[j] = cost_1\n",
    "                if center_vals[j] > cost_2:\n",
    "                    centers[j] = child2\n",
    "                    center_vals[j] = cost_2\n",
    "                    add_2_to_sol = False\n",
    "            if add_1_to_sol:\n",
    "                sol_val_new[tuple(child1)] = cost_1\n",
    "                sol_space.append(child1)\n",
    "            if add_2_to_sol:\n",
    "                sol_val_new[tuple(child2)] = cost_2\n",
    "                sol_space.append(child2)\n",
    "        centers1 = [tuple(center) for center in centers]\n",
    "       # print('center list:',centers1)\n",
    "        clusters ={center:[] for center in centers1}\n",
    "        for sol in sol_space:\n",
    "            #print('fwew',type(sol[0]))\n",
    "            #print('sol: ',sol)\n",
    "            clusters[tuple(closeset_centre(centers1,sol))].append(sol)\n",
    "        best_center =  centers1[0]\n",
    "        sol_space = clusters[best_center]\n",
    "        #print('Cluster: ',clusters)\n",
    "        #print(centers)\n",
    "        farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "        #print('sol_val:',sol_val_new)\n",
    "        for center in centers[1:]:\n",
    "            #print('eheh: ',center)\n",
    "            if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "                #print('center: ',best_center)\n",
    "                \n",
    "#                clusters[tuple(best_center)].append(center)\n",
    "                if tuple(center) in clusters:\n",
    "                    if len(clusters[tuple(center)]) >0:\n",
    "                        if tuple(center) in clusters:\n",
    "                            clusters[tuple(best_center)].append(clusters.pop(tuple(center))[0])\n",
    "        #print('Clusters: ',clusters)\n",
    "        k+=1\n",
    "        sol_vals_dict = sol_val_new\n",
    "        if len(centers) == 1:\n",
    "            print(\"Only one center is present\")\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            break\n",
    "        \n",
    "        if gas > GA_budget:\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            print('clusters:',clusters.keys())\n",
    "\n",
    "            print('GA Budget over')\n",
    "            break\n",
    "    return clusters\n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "#final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "#print(final_cluster_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"centers_items =  final_cluster_set.keys()\\ncenters = [list(i) for i in centers_items]\\nprint(centers)\\nsol_items = final_cluster_set.values()\\nfinal_clusters =[]\\n#print(sol_items)\\ncost_vals=[]\\nfor i,local_cluster in enumerate(sol_items):\\n    print(local_cluster)\\n    local_cluster=local_cluster[:2]\\n    local_cluster.append(centers[i])\\n    final_clusters.append(local_cluster)\\n    cost_vals.append(stochastic_cost_function(centers[i]))\\n    print('-'*20)\\n    print(final_clusters)\\nprint(final_clusters)\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''centers_items =  final_cluster_set.keys()\n",
    "centers = [list(i) for i in centers_items]\n",
    "print(centers)\n",
    "sol_items = final_cluster_set.values()\n",
    "final_clusters =[]\n",
    "#print(sol_items)\n",
    "cost_vals=[]\n",
    "for i,local_cluster in enumerate(sol_items):\n",
    "    print(local_cluster)\n",
    "    local_cluster=local_cluster[:2]\n",
    "    local_cluster.append(centers[i])\n",
    "    final_clusters.append(local_cluster)\n",
    "    cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "    print('-'*20)\n",
    "    print(final_clusters)\n",
    "print(final_clusters)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fitness_vals=[]\\ntotal_costs = np.sum(cost_vals)\\nfor i in range(len(cost_vals)):\\n    fitness_vals.append(cost_vals[i]/total_costs)'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fitness_vals=[]\n",
    "total_costs = np.sum(cost_vals)\n",
    "for i in range(len(cost_vals)):\n",
    "    fitness_vals.append(cost_vals[i]/total_costs)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPASS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import math\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise\n",
    "print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "def stochastic_cost_function(x:list[int],n:int):\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "        \n",
    "'''def get_n_neighbours(x: List[int], n: int, lower_bound: int = 0, upper_bound: int = 100) -> List[List[int]]:\n",
    "    neighbors = []\n",
    "    for _ in range(n):\n",
    "        mean = 0\n",
    "        std = 1\n",
    "        random_floats = mean + std * np.random.randn(len(x))\n",
    "        reach = np.round(random_floats).astype(int)\n",
    "        \n",
    "        # Create a new neighbor and ensure all values are within bounds\n",
    "        new_neighbor = []\n",
    "        for i, val in enumerate(x):\n",
    "            new_val = val + reach[i]\n",
    "            new_val = max(lower_bound, min(new_val, upper_bound))  # Clamp value between lower and upper bounds\n",
    "            new_neighbor.append(new_val)\n",
    "        \n",
    "        neighbors.append(new_neighbor)\n",
    "    \n",
    "    return neighbors'''\n",
    "\n",
    "\n",
    "#get_n_neighbours([10,10],8)\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "def euclidean_distance(list1: List[int], list2: List[int]) -> float:\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same length\")\n",
    "    \n",
    "    sum_squared_diff = sum((a - b) ** 2 for a, b in zip(list1, list2))\n",
    "    distance = math.sqrt(sum_squared_diff)\n",
    "    return distance\n",
    "from heapq import nsmallest\n",
    "\n",
    "def find_closest_keys(x_star_k: List[int], V_k: Dict[Tuple[int, ...], float], n: int = 10) -> List[Tuple[int, ...]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k.keys() \n",
    "        if key != x_star_k_tuple\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key, _ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: Dict[Tuple[int,...], float]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k.keys()) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(x_star_k, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "def check_redundancy(x_star_k : List[int], V_k:List[List[int]]):\n",
    "    x_star_k = np.array(x_star_k)\n",
    "    redundancy_status = []\n",
    "    \n",
    "    for x_i in V_k:\n",
    "        x_i = np.array(x_i)\n",
    "        model = gp.Model()\n",
    "        model.setParam('OutputFlag', 0)\n",
    "        #print('x_star: ',x_star_k)\n",
    "        n = len(x_star_k)\n",
    "        x = model.addMVar(shape=n, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "        \n",
    "        midpoint_i = (x_star_k + x_i) / 2\n",
    "        diff = x_star_k - x_i\n",
    "        \n",
    "        # Correct way to create the objective function\n",
    "        objective = gp.LinExpr()\n",
    "        for j in range(n):\n",
    "            #print('j:,',j,diff)\n",
    "            objective += diff[j] * (x[j] - midpoint_i[j])\n",
    "        model.setObjective(objective, GRB.MINIMIZE)\n",
    "        \n",
    "        for x_j in V_k:\n",
    "            if not np.array_equal(np.array(x_j), x_i):\n",
    "                x_j = np.array(x_j)\n",
    "                midpoint_j = (x_star_k + x_j) / 2\n",
    "                # Correct way to create the constraint\n",
    "                constraint = gp.LinExpr()\n",
    "                for j in range(n):\n",
    "                    #print('j: ',j)\n",
    "                    constraint += (x_star_k[j] - x_j[j]) * (x[j] - midpoint_j[j])\n",
    "                model.addConstr(constraint >= 0)\n",
    "        \n",
    "        model.optimize()\n",
    "        \n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            obj_value = model.ObjVal\n",
    "            redundancy_status.append(obj_value >= 0)\n",
    "        else:\n",
    "            redundancy_status.append(False)\n",
    "    \n",
    "    return redundancy_status\n",
    "from multiprocessing import heap\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def find_closest_keys(x_star_k: List[int], V_k: List[List[int]], n: int = 10) -> List[List[int]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    #x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k \n",
    "        if key != x_star_k\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key,_ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: List[List[int]]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(x_star_k, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "\n",
    "import random\n",
    "\n",
    "def randomly_sample_solution(population: List[List[int]],ml:int):\n",
    "    ml = min(ml,len(population))\n",
    "    return random.sample(population,ml)\n",
    "\n",
    "    \n",
    "global global_store\n",
    "global global_reps\n",
    "global_store={}\n",
    "global_reps ={}\n",
    "import gc\n",
    "def get_unique_lists(input_lists: list[list[int]]) -> list[list[int]]:\n",
    "    unique_lists = []\n",
    "    seen = set()\n",
    "    \n",
    "    for lst in input_lists:\n",
    "        tuple_lst = tuple(lst)  # Convert list to tuple for hashing\n",
    "        if tuple_lst not in seen:\n",
    "            seen.add(tuple_lst)\n",
    "            unique_lists.append(lst)\n",
    "    del tuple_lst\n",
    "    del seen\n",
    "    del input_lists\n",
    "    \n",
    "    gc.collect()  # Force garbage collection\n",
    "    \n",
    "    return unique_lists\n",
    "\n",
    "def simulate(population: List[List[int]],budget): # here population refers to the niche being explored\n",
    "    temp_heap=[]\n",
    "    global gas\n",
    "    gas = 0\n",
    "    k=2\n",
    "    #global global_store\n",
    "    \n",
    "    for i in population:\n",
    "        temp_heap.append((stochastic_cost_function(i,10),i))\n",
    "        \n",
    "    for i in temp_heap:\n",
    "        solution = tuple(i[1])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], i[0])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = i[0]\n",
    "            global_reps[solution] = 1\n",
    "        \n",
    "    heapq.heapify(temp_heap)\n",
    "    x_star_k_temp= heapq.heappop(temp_heap)\n",
    "    x_star_k = x_star_k_temp[1]\n",
    "    x_star_k_val = x_star_k_temp[0]\n",
    "    heap=[x_star_k_temp]\n",
    "    heapq.heapify(heap)\n",
    "    V_k = population\n",
    "    population.remove(x_star_k)\n",
    "    if len(population) >0:\n",
    "        for sol in population:\n",
    "            #bound = ((10**20)**(1/len(sol)))/2\n",
    "            #bound = ((10**20)**(1/4))/2 \n",
    "            #if k ==2:\n",
    "                #print('bound +-: ',bound)\n",
    "                \n",
    "            mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k) #most promising area\n",
    "            while(len(mp_area)<2):\n",
    "                mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k)\n",
    "            mp_area_vals=[ stochastic_cost_function(sol) for i in mp_area]\n",
    "            #gas += SAR(k) * len(mp_area_vals)\n",
    "            \n",
    "     \n",
    "        #print('first mp area: ',mp_area)\n",
    "    else:\n",
    "        #bound = ((10**20)**(1/len(sol)))/2\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        mp_area_vals=[ stochastic_cost_function(x_star_k) for i in mp_area]\n",
    "    for i in range(len(mp_area)):\n",
    "        solution = tuple(mp_area[i])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], mp_area_vals[i])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = mp_area_vals[i]\n",
    "            global_reps[solution] = 1\n",
    "    running = True\n",
    "    xk_store=[]\n",
    "    while running:\n",
    "        V_k += randomly_sample_solution(mp_area,100)\n",
    "        temp =[]\n",
    "        for i in range(len(V_k)):\n",
    "            temp.append((stochastic_cost_function(V_k[i]),V_k[i]))\n",
    "           # gas += SAR(k)\n",
    "       # print('V_k before prunning: ',V_k)\n",
    "        for i in temp:\n",
    "            solution = tuple(i[1])\n",
    "            if solution in global_store:\n",
    "                global_store[solution] = min(global_store[solution], i[0])\n",
    "                global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "            else:\n",
    "                global_store[solution] = i[0]\n",
    "                global_reps[solution] = 1\n",
    "        heapq.heapify(temp)\n",
    "        x_star_k_temp = heapq.heappop(temp)\n",
    "        x_star_k_val = x_star_k_temp[0]\n",
    "        x_star_k = x_star_k_temp[1]\n",
    "        V_k_temp = V_k.copy()\n",
    "        V_k_temp.remove(x_star_k)\n",
    "        redundant_variable = check_redundancy(x_star_k,V_k_temp)\n",
    "        V_k=[x_star_k]\n",
    "        for i in range(len(redundant_variable)):\n",
    "            if redundant_variable[i]:\n",
    "                V_k.append(V_k_temp[i])\n",
    "       # print('V_k post prunning: ',V_k)\n",
    "        V_k = get_unique_lists(V_k)\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        #mp_area_with_vals = [(mp_area[i],stochastic_cost_function(mp_area[i],10)) for i in range(len(mp_area))]\n",
    "        #print('mp area: ',mp_area_with_vals)\n",
    "        k+=1\n",
    "        #print('com : ', k)\n",
    "        count = 0\n",
    "        #print('Vk: ', V_k)\n",
    "        while len(mp_area) == 0 and count <=10:\n",
    "            #print('hehe: ',mp_area)\n",
    "            mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "            count +=1\n",
    "        mp_count = 0\n",
    "        if len(mp_area) ==1 :\n",
    "            if mp_count == 3:\n",
    "                print('mp area ony had one entry')\n",
    "                print('x*: ',x_star_k)\n",
    "\n",
    "                running = False\n",
    "            mp_count +=1\n",
    "        else:\n",
    "            mp_count = 0\n",
    "        if gas >budget:\n",
    "            print('x*: ',x_star_k)\n",
    "            print('COMPASS Budget Over')\n",
    "            running = False\n",
    "        #xk_store.append(x_star_k_val)\n",
    "        #print('lol')\n",
    "    return (x_star_k,x_star_k_val)#,xk_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGA TO COMPASS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outputs =[]\\nfor i,cluster in enumerate(final_clusters):\\n    continue\\n    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Outputs =[]\n",
    "for i,cluster in enumerate(final_clusters):\n",
    "    continue\n",
    "    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(values):\n",
    "    # Calculate the raw fitness values (inverse of the input values)\n",
    "    raw_fitness = [1 / (value + 1e-6) for value in values]\n",
    "    \n",
    "    # Normalize the raw fitness values so they sum to 1\n",
    "    total_fitness = sum(raw_fitness)\n",
    "    normalized_fitness = [f / total_fitness for f in raw_fitness]\n",
    "    \n",
    "    return normalized_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISC(total_budget,alpha,no_of_clusters=no_of_clusters):\n",
    "    clusters,q,r,sol_vals_dict,center_vals = initialize(500,no_of_clusters)\n",
    "    print('total budget: ',total_budget)\n",
    "    print('no of clusters: ', no_of_clusters)\n",
    "    #print('ini')\n",
    "    final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "    #print('evo')\n",
    "    centers_items =  final_cluster_set.keys()\n",
    "    centers = [list(i) for i in centers_items]\n",
    "    #print(centers)\n",
    "    sol_items = final_cluster_set.values()\n",
    "    final_clusters =[]\n",
    "    #print(sol_items)\n",
    "    cost_vals=[]\n",
    "    assign_budgets(total_budget,alpha=alpha)\n",
    "    for i,local_cluster in enumerate(sol_items):\n",
    "        #print(local_cluster)\n",
    "        local_cluster=local_cluster[:2]\n",
    "        local_cluster.append(centers[i])\n",
    "        final_clusters.append(local_cluster)\n",
    "        cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "        #print('-'*20)\n",
    "        #print(final_clusters)\n",
    "    #print(final_clusters)\n",
    "    fitness_vals=fitness_function(cost_vals)\n",
    "    \n",
    "    '''total_costs = np.sum(cost_vals)\n",
    "    for i in range(len(cost_vals)):\n",
    "        fitness_vals.append(abs(total_costs/cost_vals[i]))\n",
    "    '''\n",
    "    print('fitness: ',fitness_vals)\n",
    "    Outputs =[]\n",
    "    for i,cluster in enumerate(final_clusters):\n",
    "        print('i=' ,i)\n",
    "        Outputs.append(simulate(cluster,compass_budget*(fitness_vals[i])))\n",
    "    sorted_outputs = sorted(Outputs,key= lambda x:x[1])\n",
    "   # print(sorted_outputs[0])\n",
    "    return sorted_outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total budget:  20000.0\n",
      "no of clusters:  4\n",
      "clusters: dict_keys([(-32, 10, 7, -29)])\n",
      "GA Budget over\n",
      "fitness:  [1.0]\n",
      "i= 0\n",
      "x*:  [-1, 0, 1, 0]\n",
      "COMPASS Budget Over\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-1, 0, 1, 0], 36.75367448934058)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISC(total_budget,alpha,no_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clustering_outcomes = []\\nimport gc\\nimport matplotlib.pyplot as plt\\n\\n# Iterate over ratio_ga_compass and cluster_count values\\nfor ratio in np.arange(0.6, 0.9, 0.1):  # Include 1.0 in the range\\n    for clusters in range(3, 6):  # cluster_count values from 1 to 5\\n        print(f'ratio_ga_compass = {ratio:.1f}, cluster_count = {clusters}')\\n        \\n        # Run improved_stochastic_clustering 4 times and keep the minimum\\n        best_value = float('inf')\\n        best_configuration = None\\n        for _ in range(4):\\n            print(_)\\n            configuration, performance = ISC(total_budget, ratio, clusters)\\n            if performance < best_value:\\n                best_value = performance\\n                best_configuration = configuration\\n        print('-'*20)\\n        clustering_outcomes.append((ratio, clusters, best_value))\\n        print(f'Best performance after 4 runs: {best_value}')\\n        # Define the variables you want to keep\\n        \\n# Convert clustering_outcomes to a numpy array for easier manipulation\\noutcome_array = np.array(clustering_outcomes)\\n\\n# Create a plot for each ratio value\\nfor ratio in np.unique(outcome_array[:, 0]):\\n    plt.figure(figsize=(10, 6))\\n    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\\n    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o')\\n    \\n    plt.title(f'Best Performance for Ratio={ratio:.1f} (4 runs each)')\\n    plt.xlabel('Number of Clusters')\\n    plt.ylabel('Best Performance Value')\\n    plt.grid(True)\\n    #plt.savefig(f'performance_ratio_{ratio:.1f}.png')\\n    plt.close()\\n\\n# Create a single plot with all ratio values\\nplt.figure(figsize=(12, 8))\\nfor ratio in np.unique(outcome_array[:, 0]):\\n    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\\n    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o', label=f'Ratio={ratio:.1f}')\\n\\nplt.title('Best Performance for Different Ratios and Cluster Counts (4 runs each)')\\nplt.xlabel('Number of Clusters')\\nplt.ylabel('Best Performance Value')\\nplt.legend()\\nplt.grid(True)\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clustering_outcomes = []\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over ratio_ga_compass and cluster_count values\n",
    "for ratio in np.arange(0.6, 0.9, 0.1):  # Include 1.0 in the range\n",
    "    for clusters in range(3, 6):  # cluster_count values from 1 to 5\n",
    "        print(f'ratio_ga_compass = {ratio:.1f}, cluster_count = {clusters}')\n",
    "        \n",
    "        # Run improved_stochastic_clustering 4 times and keep the minimum\n",
    "        best_value = float('inf')\n",
    "        best_configuration = None\n",
    "        for _ in range(4):\n",
    "            print(_)\n",
    "            configuration, performance = ISC(total_budget, ratio, clusters)\n",
    "            if performance < best_value:\n",
    "                best_value = performance\n",
    "                best_configuration = configuration\n",
    "        print('-'*20)\n",
    "        clustering_outcomes.append((ratio, clusters, best_value))\n",
    "        print(f'Best performance after 4 runs: {best_value}')\n",
    "        # Define the variables you want to keep\n",
    "        \n",
    "# Convert clustering_outcomes to a numpy array for easier manipulation\n",
    "outcome_array = np.array(clustering_outcomes)\n",
    "\n",
    "# Create a plot for each ratio value\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o')\n",
    "    \n",
    "    plt.title(f'Best Performance for Ratio={ratio:.1f} (4 runs each)')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Best Performance Value')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(f'performance_ratio_{ratio:.1f}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create a single plot with all ratio values\n",
    "plt.figure(figsize=(12, 8))\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o', label=f'Ratio={ratio:.1f}')\n",
    "\n",
    "plt.title('Best Performance for Different Ratios and Cluster Counts (4 runs each)')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Best Performance Value')\n",
    "plt.legend()\n",
    "plt.grid(True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 100, 99, 88],\n",
       " [97, 99, 100, 100],\n",
       " [100, 100, 100, 100],\n",
       " [99, 94, 100, 89],\n",
       " [99, 91, 93, 94],\n",
       " [100, 100, 99, 100]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_neighbours([100,100,100,100],6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
