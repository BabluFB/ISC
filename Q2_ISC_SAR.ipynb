{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hehe\n"
     ]
    }
   ],
   "source": [
    "print('hehe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER DEFINED VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound = -100\n",
    "up_bound = 100\n",
    "no_of_clusters =2\n",
    "solution_dimension = 4\n",
    "total_budget = 3e5\n",
    "alpha = 0.6\n",
    "no_of_neighbours = 40\n",
    "step_size_param = 10 # never changes\n",
    "step_size = step_size_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 14], [17, 1], [1, 6], [-1, 5], [8, 17], [6, -5], [16, 16], [-3, 3]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import math\n",
    "def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise\n",
    "def stochastic_cost_function(x:list[int],n:int = 10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])\n",
    "\n",
    "\n",
    "def get_n_neighbours(x: list[int], n: int = no_of_neighbours, lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    neighbors = []\n",
    "    global step_size\n",
    "    x_temp = x.copy()\n",
    "    #print('step_size: ',step_size)\n",
    "    for i in range(n):\n",
    "        reach = np.floor(step_size * np.random.randn(len(x)))  # normal distribution with 0 mean and (step_size) std\n",
    "        \n",
    "        # Apply reach element-wise to x\n",
    "        #print('reach: ',reach)\n",
    "        new_neighbor = np.clip(np.array(x) + reach, lower_bound, upper_bound)\n",
    "        new_neighbor = np.round(new_neighbor).astype(int)\n",
    "        neighbors.append(list(new_neighbor))\n",
    "    return neighbors\n",
    "k = 2\n",
    "def SAR(k):\n",
    "    \n",
    "    n0=8\n",
    "    return math.ceil(n0*(np.log(k)**2))\n",
    "get_n_neighbours([10,10],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_budget = 1e4\n",
    "GA_budget = 0\n",
    "compass_budget = 0\n",
    "def assign_budgets(total_budget,alpha =alpha):\n",
    "    global GA_budget , compass_budget\n",
    "    #alpha = 0.5\n",
    "    GA_budget = total_budget*alpha\n",
    "    compass_budget = total_budget*(1-alpha)\n",
    "assign_budgets(total_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-60, 93, -70, -11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import heapq, random\n",
    "#global gas \n",
    "gas = 0\n",
    "def create_genome(n,lower_bound =low_bound,upper_bound=up_bound):\n",
    "    return [random.randint(lower_bound, upper_bound) for _ in range(n)]\n",
    "    #return [np.random.randint(lower_bound,upper_bound) for _ in range(n)]\n",
    "print(create_genome(4))\n",
    "\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise'''\n",
    "#print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "'''def stochastic_cost_function(x:list[int],n:int=10):\n",
    "    global gas\n",
    "    gas += n\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "\n",
    "def euclidean_distance(centre_1 : List[int],centre_2: List[int]):\n",
    "    array1 = np.array(centre_1)\n",
    "    array2 = np.array(centre_2)\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(array1 - array2)\n",
    "    return euclidean_distance\n",
    "\n",
    "def find_farthest_point(center: List[int], sol_space: List[List[int]]) -> Tuple[List[int], float]: #Finds the farthest point in the solution space from the centre\n",
    "    max_distance = 0\n",
    "    farthest_point = None\n",
    "    \n",
    "    for point in sol_space:\n",
    "        # Calculate the squared distance\n",
    "        squared_distance = sum((c - p)**2 for c, p in zip(center, point))\n",
    "        \n",
    "        if squared_distance > max_distance:\n",
    "            max_distance = squared_distance\n",
    "            farthest_point = point\n",
    "    \n",
    "    # Calculate the actual distance (square root of the squared distance)\n",
    "    max_distance = np.sqrt(max_distance)\n",
    "    \n",
    "    return farthest_point, max_distance\n",
    "\n",
    "def closeset_centre(centers:List[List[int]],visited_solution:List[int]) -> List[int]:#Finds the closests centre to the point\n",
    "    closest = [float('inf') for _ in centers]\n",
    "    min_dist= float('inf')\n",
    "    for center in centers:\n",
    "        dist =euclidean_distance(center,visited_solution)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = center\n",
    "        #print('hehe: ',closest)\n",
    "    return closest\n",
    "#INITIALIZATION STEP\n",
    "def initialize(mg:int,q:int = no_of_clusters,n:int = solution_dimension) : #n is dimension of solution vector and mg is number of solns sampled\n",
    "    #n=4\n",
    "    global gas,k , low_bound, up_bound\n",
    "    unique_set = {}\n",
    "    while len(unique_set) <mg: # Sampling Mg Solutions from the feasible set\n",
    "        temp_lower_bound = int((low_bound*3/4) + (up_bound*1/4)) \n",
    "        temp_upper_bound = int((low_bound*1/4) + (up_bound*3/4))\n",
    "        #print('sadas',temp_lower_bound,temp_upper_bound)\n",
    "        genome = create_genome(n,temp_lower_bound,temp_upper_bound)\n",
    "        if tuple(genome) in unique_set:\n",
    "            unique_set[tuple(genome)] = min(unique_set[tuple(genome)],stochastic_cost_function(genome))\n",
    "        else:\n",
    "            unique_set[tuple(genome)] = stochastic_cost_function(genome)\n",
    "    \n",
    "    heap = [(value,key) for key,value in unique_set.items()]\n",
    "    heapq.heapify(heap)\n",
    "    sorted_items = sorted(unique_set.items(), key=lambda x: x[1])\n",
    "    #Selecting q best solutions as nice centres \n",
    "    niche_centers = sorted_items[:q]\n",
    "    sol_space = sorted_items[q:]\n",
    "    centers = [center[0] for center in niche_centers]\n",
    "    clusters ={center:[] for center in centers}\n",
    "    for sol in sol_space:\n",
    "        clusters[tuple(closeset_centre(centers,sol[0]))].append(sol[0])\n",
    "    best_center =  centers[0]\n",
    "    sol_space = clusters[best_center]\n",
    "    #print('Cluster: ',clusters)\n",
    "    farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "    \n",
    "    for center in centers[1:]:\n",
    "        if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "            clusters[tuple(best_center)].append(center)\n",
    "            #print('cluster', clusters)\n",
    "            if len(clusters[center])  > 0:\n",
    "                clusters[tuple(best_center)].append(clusters.pop(center)[0])\n",
    "    centers_remaining = [list(key) for key in clusters.keys()][1:]\n",
    "    r = float('inf')\n",
    "    for center in centers_remaining:\n",
    "        r = min(euclidean_distance(center,best_center),r)\n",
    "    r = r//2\n",
    "    q = len(clusters.keys())\n",
    "    sol_vals_dict = {} # maps each solution to closest center\n",
    "\n",
    "   # print('clus: ',clusters)\n",
    "    for key, list_of_lists in clusters.items():\n",
    "       # print('lol: ',list_of_lists)\n",
    "        for lst in list_of_lists:\n",
    "           # print('lst: ',lst)\n",
    "            sol_vals_dict[tuple(lst)] = unique_set[tuple(lst)]\n",
    "\n",
    "    center_vals ={}\n",
    "    for center in clusters.keys():\n",
    "        center_vals[center] = stochastic_cost_function(center)\n",
    "    k +=1 \n",
    "    #print('ini ; ', k)\n",
    "    return clusters , q , r , sol_vals_dict , center_vals\n",
    "    \n",
    "    \n",
    "#clusters,q,r,sol_vals_dict,center_vals = initialize(4,200,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_pair_in_range(dictionary: Dict[Tuple[int], int], lower_bound: int = low_bound, upper_bound: int = up_bound):\n",
    "    eligible_pairs = [(key, value) for key, value in dictionary.items() \n",
    "                      if lower_bound <= value <= upper_bound]\n",
    "    #for key,value in dictionary.items():\n",
    "        #print(value)\n",
    "   # print('e[ :',eligible_pairs)\n",
    "    if not eligible_pairs:\n",
    "        return None  # No pairs found within the specified range\n",
    "    \n",
    "    return eligible_pairs[np.random.choice(len(eligible_pairs))][0]\n",
    "\n",
    "def get_mate(genome: List[int], sol_val_dict: Dict[Tuple[int], int]):\n",
    "    temp_dict = sol_val_dict.copy()  # Create a copy of the original dictionary\n",
    "    cost_value = temp_dict[tuple(genome)]  # Get the cost value for the genome\n",
    "    \n",
    "    del temp_dict[tuple(genome)]  # Remove the genome from the dictionary\n",
    "    \n",
    "    beta = 0.1\n",
    "    #print('sol_val: ',len(sol_val_dict))\n",
    "    mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "    #print('mate: ',mate)\n",
    "    counter= 0 \n",
    "    while not mate or list(mate) == genome:\n",
    "        if counter > 10:\n",
    "            mate = genome\n",
    "            break\n",
    "        #print('alppha: ',alpha)\n",
    "        #print('12312')\n",
    "        #Increasing visible space for finding mate\n",
    "        beta += 0.1\n",
    "        mate = select_random_pair_in_range(temp_dict, (1 - beta) * cost_value, (1 + beta) * cost_value)\n",
    "        counter +=1\n",
    "    \n",
    "    return list(mate)\n",
    "\n",
    "def single_point_crossover(parent1, parent2):\n",
    "    size = len(parent1)\n",
    "    parent1 = tuple(parent1)\n",
    "    parent2 = tuple(parent2)\n",
    "    # Choose a random crossover point (excluding the first and last positions)\n",
    "    crossover_point = np.random.randint(1, size )\n",
    "    \n",
    "    # Create the first child\n",
    "    child1 = list(parent1[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer1 = crossover_point\n",
    "    for gene in parent2[crossover_point:] + parent2[:crossover_point]:\n",
    "        if gene not in child1:\n",
    "            child1[pointer1] = gene\n",
    "            pointer1 += 1\n",
    "            if pointer1 == size:\n",
    "                pointer1 = 0\n",
    "    \n",
    "    # Create the second child\n",
    "    child2 = list(parent2[:crossover_point] + tuple([-1] * (size - crossover_point)))\n",
    "    pointer2 = crossover_point\n",
    "    for gene in parent1[crossover_point:] + parent1[:crossover_point]:\n",
    "        if gene not in child2:\n",
    "            child2[pointer2] = gene\n",
    "            pointer2 += 1\n",
    "            if pointer2 == size:\n",
    "                pointer2 = 0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "def evolution(clusters,sol_vals_dict,center_vals_dict):\n",
    "    global k\n",
    "    centers = center_vals_dict.keys()\n",
    "    centers = [list(center) for center in centers]\n",
    "    center_vals = center_vals_dict.values()\n",
    "    center_vals = [val for val in center_vals]\n",
    "    while True:\n",
    "        sorted_items = sorted(sol_vals_dict.items(), key=lambda x: x[1])\n",
    "        #elite_genome = sorted_items[:5]\n",
    "        other_genomes = sorted_items\n",
    "        #elite_genomes = [temp[0] for temp in elite_genome]\n",
    "        other_genomes = [list(genome[0]) for genome in other_genomes]    \n",
    "            \n",
    "        \n",
    "        #print('pther_genomes: ',other_genomes)\n",
    "        #print('centers',centers)\n",
    "        m =len(other_genomes)\n",
    "        sol_val_new ={}\n",
    "        sol_space=[]\n",
    "        unique_set= set()\n",
    "        for _ in range(m):\n",
    "            #print('glob: ',k)\n",
    "\n",
    "            i =np.random.randint(0,m)\n",
    "            parent1 = other_genomes[i]\n",
    "            parent2 = get_mate(parent1,sol_vals_dict)\n",
    "            #print('qeqw')\n",
    "            child1,child2 = single_point_crossover(parent1,parent2)\n",
    "            cost_1 = stochastic_cost_function(child1)\n",
    "            cost_2 = stochastic_cost_function(child2)\n",
    "            add_1_to_sol = True\n",
    "            add_2_to_sol = True\n",
    "            unique_set.add(tuple(child1))\n",
    "            unique_set.add(tuple(child2))\n",
    "            #print('center_vals: ',center_vals)\n",
    "            for j in range(len(center_vals)):\n",
    "                if center_vals[j] > cost_1:\n",
    "                    add_1_to_sol = False\n",
    "                    centers[j] = child1\n",
    "                    center_vals[j] = cost_1\n",
    "                if center_vals[j] > cost_2:\n",
    "                    centers[j] = child2\n",
    "                    center_vals[j] = cost_2\n",
    "                    add_2_to_sol = False\n",
    "            if add_1_to_sol:\n",
    "                sol_val_new[tuple(child1)] = cost_1\n",
    "                sol_space.append(child1)\n",
    "            if add_2_to_sol:\n",
    "                sol_val_new[tuple(child2)] = cost_2\n",
    "                sol_space.append(child2)\n",
    "        centers1 = [tuple(center) for center in centers]\n",
    "       # print('center list:',centers1)\n",
    "        clusters ={center:[] for center in centers1}\n",
    "        for sol in sol_space:\n",
    "            #print('fwew',type(sol[0]))\n",
    "            #print('sol: ',sol)\n",
    "            clusters[tuple(closeset_centre(centers1,sol))].append(sol)\n",
    "        best_center =  centers1[0]\n",
    "        sol_space = clusters[best_center]\n",
    "        #print('Cluster: ',clusters)\n",
    "        #print(centers)\n",
    "        farthest_point , min_radius = find_farthest_point(best_center,centers[1:])\n",
    "        #print('sol_val:',sol_val_new)\n",
    "        for center in centers[1:]:\n",
    "            #print('eheh: ',center)\n",
    "            if euclidean_distance(center,best_center) < 0.5*min_radius:\n",
    "                #print('center: ',best_center)\n",
    "                \n",
    "#                clusters[tuple(best_center)].append(center)\n",
    "                if tuple(center) in clusters:\n",
    "                    if len(clusters[tuple(center)]) >0:\n",
    "                        if tuple(center) in clusters:\n",
    "                            clusters[tuple(best_center)].append(clusters.pop(tuple(center))[0])\n",
    "        #print('Clusters: ',clusters)\n",
    "        k+=1\n",
    "        sol_vals_dict = sol_val_new\n",
    "        if len(centers) == 1:\n",
    "            print(\"Only one center is present\")\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            break\n",
    "        \n",
    "        if gas > GA_budget:\n",
    "            #print('no of centers: ',len(clusters))\n",
    "            print('clusters:',clusters.keys())\n",
    "\n",
    "            print('GA Budget over')\n",
    "            break\n",
    "    return clusters\n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "#final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "#print(final_cluster_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"centers_items =  final_cluster_set.keys()\\ncenters = [list(i) for i in centers_items]\\nprint(centers)\\nsol_items = final_cluster_set.values()\\nfinal_clusters =[]\\n#print(sol_items)\\ncost_vals=[]\\nfor i,local_cluster in enumerate(sol_items):\\n    print(local_cluster)\\n    local_cluster=local_cluster[:2]\\n    local_cluster.append(centers[i])\\n    final_clusters.append(local_cluster)\\n    cost_vals.append(stochastic_cost_function(centers[i]))\\n    print('-'*20)\\n    print(final_clusters)\\nprint(final_clusters)\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''centers_items =  final_cluster_set.keys()\n",
    "centers = [list(i) for i in centers_items]\n",
    "print(centers)\n",
    "sol_items = final_cluster_set.values()\n",
    "final_clusters =[]\n",
    "#print(sol_items)\n",
    "cost_vals=[]\n",
    "for i,local_cluster in enumerate(sol_items):\n",
    "    print(local_cluster)\n",
    "    local_cluster=local_cluster[:2]\n",
    "    local_cluster.append(centers[i])\n",
    "    final_clusters.append(local_cluster)\n",
    "    cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "    print('-'*20)\n",
    "    print(final_clusters)\n",
    "print(final_clusters)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fitness_vals=[]\\ntotal_costs = np.sum(cost_vals)\\nfor i in range(len(cost_vals)):\\n    fitness_vals.append(cost_vals[i]/total_costs)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fitness_vals=[]\n",
    "total_costs = np.sum(cost_vals)\n",
    "for i in range(len(cost_vals)):\n",
    "    fitness_vals.append(cost_vals[i]/total_costs)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPASS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import math\n",
    "'''def stochastic_cost_function_helper(x:list[int]): #here x holds [x1,x2,x3,.....]\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Extract individual elements\n",
    "    x1, x2, x3, x4 = x\n",
    "    \n",
    "    # Compute the deterministic part of the expression\n",
    "    result = (x1 + 10 * x2)**2 + 5 * (x3 - x4)**2 + (x2 - 2 * x3)**4 + 10 * (x1 - x4)**4 + 1\n",
    "    \n",
    "    noise = np.random.normal(0, np.sqrt(result))\n",
    "    \n",
    "    result_with_noise = result + noise\n",
    "    \n",
    "    return result_with_noise\n",
    "print(stochastic_cost_function_helper([0,0,0,0]))\n",
    "#stochastic_cost_function(0)   \n",
    "def stochastic_cost_function(x:list[int],n:int):\n",
    "    return np.mean([stochastic_cost_function_helper(x) for _ in range(n)])'''\n",
    "        \n",
    "'''def get_n_neighbours(x: List[int], n: int, lower_bound: int = 0, upper_bound: int = 100) -> List[List[int]]:\n",
    "    neighbors = []\n",
    "    for _ in range(n):\n",
    "        mean = 0\n",
    "        std = 1\n",
    "        random_floats = mean + std * np.random.randn(len(x))\n",
    "        reach = np.round(random_floats).astype(int)\n",
    "        \n",
    "        # Create a new neighbor and ensure all values are within bounds\n",
    "        new_neighbor = []\n",
    "        for i, val in enumerate(x):\n",
    "            new_val = val + reach[i]\n",
    "            new_val = max(lower_bound, min(new_val, upper_bound))  # Clamp value between lower and upper bounds\n",
    "            new_neighbor.append(new_val)\n",
    "        \n",
    "        neighbors.append(new_neighbor)\n",
    "    \n",
    "    return neighbors'''\n",
    "\n",
    "\n",
    "#get_n_neighbours([10,10],8)\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "def euclidean_distance(list1: List[int], list2: List[int]) -> float:\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same length\")\n",
    "    \n",
    "    sum_squared_diff = sum((a - b) ** 2 for a, b in zip(list1, list2))\n",
    "    distance = math.sqrt(sum_squared_diff)\n",
    "    return distance\n",
    "from heapq import nsmallest\n",
    "\n",
    "def find_closest_keys(x_star_k: List[int], V_k: Dict[Tuple[int, ...], float], n: int = 10) -> List[Tuple[int, ...]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k.keys() \n",
    "        if key != x_star_k_tuple\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key, _ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: Dict[Tuple[int,...], float]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k.keys()) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(sol, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "def check_redundancy(x_star_k : List[int], V_k:List[List[int]]):\n",
    "    x_star_k = np.array(x_star_k)\n",
    "    redundancy_status = []\n",
    "    \n",
    "    for x_i in V_k:\n",
    "        x_i = np.array(x_i)\n",
    "        model = gp.Model()\n",
    "        model.setParam('OutputFlag', 0)\n",
    "        #print('x_star: ',x_star_k)\n",
    "        n = len(x_star_k)\n",
    "        x = model.addMVar(shape=n, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "        \n",
    "        midpoint_i = (x_star_k + x_i) / 2\n",
    "        diff = x_star_k - x_i\n",
    "        \n",
    "        # Correct way to create the objective function\n",
    "        objective = gp.LinExpr()\n",
    "        for j in range(n):\n",
    "            #print('j:,',j,diff)\n",
    "            objective += diff[j] * (x[j] - midpoint_i[j])\n",
    "        model.setObjective(objective, GRB.MINIMIZE)\n",
    "        \n",
    "        for x_j in V_k:\n",
    "            if not np.array_equal(np.array(x_j), x_i):\n",
    "                x_j = np.array(x_j)\n",
    "                midpoint_j = (x_star_k + x_j) / 2\n",
    "                # Correct way to create the constraint\n",
    "                constraint = gp.LinExpr()\n",
    "                for j in range(n):\n",
    "                    #print('j: ',j)\n",
    "                    constraint += (x_star_k[j] - x_j[j]) * (x[j] - midpoint_j[j])\n",
    "                model.addConstr(constraint >= 0)\n",
    "        \n",
    "        model.optimize()\n",
    "        \n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            obj_value = model.ObjVal\n",
    "            redundancy_status.append(obj_value >= 0)\n",
    "        else:\n",
    "            redundancy_status.append(False)\n",
    "    \n",
    "    return redundancy_status\n",
    "from multiprocessing import heap\n",
    "from typing import List\n",
    "\n",
    "import time\n",
    "def find_closest_keys(x_star_k: List[int], V_k: List[List[int]], n: int = 10) -> List[List[int]]:\n",
    "    def euclidean_distance(a, b):\n",
    "        return np.sqrt(sum((x - y) ** 2 for x, y in zip(a, b)))\n",
    "    \n",
    "    #x_star_k_tuple = tuple(x_star_k)\n",
    "    \n",
    "    distances = [\n",
    "        (key, euclidean_distance(x_star_k, key)) \n",
    "        for key in V_k \n",
    "        if key != x_star_k\n",
    "    ]\n",
    "    \n",
    "    closest_keys = nsmallest(n, distances, key=lambda x: x[1])\n",
    "    return [key for key,_ in closest_keys]\n",
    "\n",
    "def get_most_promising_area(x_star_k:List[int],neighbours: List[List[int]], V_k: List[List[int]]):\n",
    "    mp_area=[]\n",
    "    closest_keys = find_closest_keys(x_star_k,V_k,10)\n",
    "    if len(V_k) ==0:\n",
    "        return neighbours\n",
    "    for sol in neighbours:\n",
    "        sol_distance = euclidean_distance(x_star_k, sol)\n",
    "        \n",
    "        # Check if sol is closer to x_star_k than the other closest keys\n",
    "        is_closer = all(sol_distance < euclidean_distance(sol, key) for key in closest_keys)\n",
    "        \n",
    "        if is_closer:\n",
    "            mp_area.append(sol)\n",
    "    \n",
    "    return mp_area\n",
    "\n",
    "import random\n",
    "\n",
    "def randomly_sample_solution(population: List[List[int]],ml:int):\n",
    "    ml = min(ml,len(population))\n",
    "    return random.sample(population,ml)\n",
    "\n",
    "    \n",
    "global global_store\n",
    "global global_reps\n",
    "global_store={}\n",
    "global_reps ={}\n",
    "import gc\n",
    "def get_unique_lists(input_lists: list[list[int]]) -> list[list[int]]:\n",
    "    unique_lists = []\n",
    "    seen = set()\n",
    "    \n",
    "    for lst in input_lists:\n",
    "        tuple_lst = tuple(lst)  # Convert list to tuple for hashing\n",
    "        if tuple_lst not in seen:\n",
    "            seen.add(tuple_lst)\n",
    "            unique_lists.append(lst)\n",
    "    seen = set()\n",
    "    \n",
    "    return unique_lists\n",
    "cycle_time_store=[]\n",
    "\n",
    "import osqp\n",
    "from scipy import sparse\n",
    "\n",
    "def check_redundancy_osqp(x_star_k: List[int], V_k: List[List[int]]):\n",
    "    \"\"\"\n",
    "    Refactored function that checks redundancy of vectors using OSQP for faster performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_star_k: Reference vector as a list of integers.\n",
    "    - V_k: List of vectors representing the solution space.\n",
    "    \n",
    "    Returns:\n",
    "    - List of boolean values indicating whether each vector is redundant.\n",
    "    \"\"\"\n",
    "    x_star_k = np.array(x_star_k)\n",
    "    redundancy_status = []\n",
    "    \n",
    "    # Iterate over each vector x_i in V_k\n",
    "    for x_i in V_k:\n",
    "        x_i = np.array(x_i)\n",
    "        n = len(x_star_k)\n",
    "        \n",
    "        # Set up the problem in standard quadratic form: \n",
    "        # min (1/2) * x^T P x + q^T x \n",
    "        # subject to Ax >= l\n",
    "        \n",
    "        # Objective P and q\n",
    "        diff = (x_star_k - x_i)\n",
    "        P = sparse.diags([1.0] * n)  # Quadratic term (Identity matrix for simplicity)\n",
    "        q = -diff @ (x_star_k + x_i) / 2  # Linear term\n",
    "        \n",
    "        # Constraints\n",
    "        A_data = []\n",
    "        l_data = []\n",
    "        \n",
    "        for x_j in V_k:\n",
    "            if not np.array_equal(np.array(x_j), x_i):\n",
    "                x_j = np.array(x_j)\n",
    "                midpoint_j = (x_star_k + x_j) / 2\n",
    "                constraint = (x_star_k - x_j)\n",
    "                A_data.append(constraint)\n",
    "                l_data.append(midpoint_j @ constraint)\n",
    "        \n",
    "        A = sparse.vstack([sparse.csc_matrix(np.array(A_data))])\n",
    "        l = np.array(l_data)\n",
    "\n",
    "        # Set bounds for x (no upper bound needed for OSQP, we use lower bounds as per constraints)\n",
    "        u = np.inf * np.ones_like(l)\n",
    "\n",
    "        # Setup OSQP problem\n",
    "        solver = osqp.OSQP()\n",
    "        solver.setup(P=P, q=q, A=A, l=l, u=u, verbose=False)\n",
    "        \n",
    "        # Solve the problem\n",
    "        res = solver.solve()\n",
    "        \n",
    "        # Check if the solution is redundant (objective value >= 0)\n",
    "        if res.info.status == 'solved':\n",
    "            obj_value = res.info.obj_val\n",
    "            redundancy_status.append(obj_value >= 0)\n",
    "        else:\n",
    "            redundancy_status.append(False)\n",
    "    \n",
    "    return redundancy_status\n",
    "\n",
    "def simulate(population: List[List[int]],budget): # here population refers to the niche being explored\n",
    "    temp_heap=[]\n",
    "    global gas, step_size, step_size_param\n",
    "    global no_of_cycle_steps,cycle_time_store\n",
    "    gas = 0\n",
    "    k=2\n",
    "    #global global_store\n",
    "    \n",
    "    for i in population:\n",
    "        temp_heap.append((stochastic_cost_function(i,10),i))\n",
    "        \n",
    "    for i in temp_heap:\n",
    "        solution = tuple(i[1])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], i[0])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = i[0]\n",
    "            global_reps[solution] = 1\n",
    "        \n",
    "    heapq.heapify(temp_heap)\n",
    "    x_star_k_temp= heapq.heappop(temp_heap)\n",
    "    x_star_k = x_star_k_temp[1]\n",
    "    x_star_k_val = x_star_k_temp[0]\n",
    "    heap=[x_star_k_temp]\n",
    "    #heapq.heapify(heap)\n",
    "    V_k = population\n",
    "    population.remove(x_star_k)\n",
    "    if len(population) >0:\n",
    "        for sol in population:\n",
    "            #bound = ((10**20)**(1/len(sol)))/2\n",
    "            #bound = ((10**20)**(1/4))/2 \n",
    "            #if k ==2:\n",
    "                #print('bound +-: ',bound)\n",
    "                \n",
    "            mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k) #most promising area\n",
    "            while(len(mp_area)<2):\n",
    "                mp_area = get_most_promising_area(sol,get_n_neighbours(sol),V_k)\n",
    "            mp_area_vals=[ stochastic_cost_function(sol) for i in mp_area]\n",
    "            #gas += SAR(k) * len(mp_area_vals)\n",
    "            \n",
    "     \n",
    "        #print('first mp area: ',mp_area)\n",
    "    else:\n",
    "        #bound = ((10**20)**(1/len(sol)))/2\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        mp_area_vals=[ stochastic_cost_function(x_star_k) for i in mp_area]\n",
    "    for i in range(len(mp_area)):\n",
    "        solution = tuple(mp_area[i])\n",
    "        if solution in global_store:\n",
    "            global_store[solution] = min(global_store[solution], mp_area_vals[i])\n",
    "            global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "        else:\n",
    "            global_store[solution] = mp_area_vals[i]\n",
    "            global_reps[solution] = 1\n",
    "    running = True\n",
    "    xk_store=[]\n",
    "    V_k =[x_star_k]\n",
    "    while running:\n",
    "        no_of_cycle_steps+=1\n",
    "        cycle_time = time.time()\n",
    "        time_curr = time.time()\n",
    "        V_k += randomly_sample_solution(mp_area,40)\n",
    "        #print('sampling time: ', time.time()-time_curr)\n",
    "        time_curr = time.time()\n",
    "\n",
    "        temp =[]\n",
    "        for i in range(len(V_k)):\n",
    "            temp.append((stochastic_cost_function(V_k[i]),V_k[i]))\n",
    "           # gas += SAR(k)\n",
    "       # print('V_k before prunning: ',V_k)\n",
    "        #print('cost calculating time: ', time.time()-time_curr)\n",
    "\n",
    "        time_curr = time.time()\n",
    "\n",
    "        for i in temp:\n",
    "            solution = tuple(i[1])\n",
    "            if solution in global_store:\n",
    "                global_store[solution] = min(global_store[solution], i[0])\n",
    "                #global_reps[solution] = global_reps.get(solution, 0) + 1\n",
    "            else:\n",
    "                global_store[solution] = i[0]\n",
    "                #global_reps[solution] = 1\n",
    "        #print('global time: ', time.time()-time_curr)\n",
    "            \n",
    "        time_curr = time.time()\n",
    "        heapq.heapify(temp)\n",
    "        #print('heaping time: ', time.time()-time_curr)\n",
    "\n",
    "        x_star_k_temp = heapq.heappop(temp)\n",
    "        x_star_k_val = x_star_k_temp[0]\n",
    "        x_star_k = x_star_k_temp[1]\n",
    "        V_k_temp = V_k.copy()\n",
    "        V_k_temp.remove(x_star_k)\n",
    "        time_curr = time.time()\n",
    "        redundant_variable = check_redundancy(x_star_k,V_k_temp)#[1 for _ in range(len(V_k_temp))]#check_redundancy(x_star_k,V_k_temp)\n",
    "        #print('grobi time: ', time.time()-time_curr)\n",
    "        V_k=[x_star_k]\n",
    "        for i in range(len(redundant_variable)):\n",
    "            if redundant_variable[i]:\n",
    "                V_k.append(V_k_temp[i])\n",
    "        #print('V_k post prunning: ',V_k)\n",
    "        time_curr = time.time()\n",
    "\n",
    "        V_k = get_unique_lists(V_k)\n",
    "        mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "        #print('vk and mp time: ', time.time()-time_curr)\n",
    "\n",
    "        #mp_area_with_vals = [(mp_area[i],stochastic_cost_function(mp_area[i],10)) for i in range(len(mp_area))]\n",
    "        #print('mp area: ',mp_area_with_vals)\n",
    "        k+=1\n",
    "        #print('com : ', k)\n",
    "        count = 0\n",
    "        #print('Vk: ', V_k)\n",
    "        while len(mp_area) == 0 and count <=10:\n",
    "            #print('hehe: ',mp_area)\n",
    "            mp_area = get_most_promising_area(x_star_k,get_n_neighbours(x_star_k),V_k)\n",
    "            count +=1\n",
    "        mp_count = 0\n",
    "        if len(mp_area) ==1 :\n",
    "            if mp_count == 3:\n",
    "                print('mp area ony had one entry')\n",
    "                print('x*: ',x_star_k)\n",
    "\n",
    "                running = False\n",
    "            mp_count +=1\n",
    "        else:\n",
    "            mp_count = 0\n",
    "        if gas >budget:\n",
    "            print('x*: ',x_star_k)\n",
    "            print('COMPASS Budget Over')\n",
    "            running = False\n",
    "        if gas >= (8*budget)//10:\n",
    "            step_size = 1\n",
    "        elif gas >= (7*budget)//10:\n",
    "            step_size = step_size_param//2\n",
    "        elif gas >= (6*step_size_param)//10:\n",
    "            step_size = (3* step_size_param)//4\n",
    "        #xk_store.append(x_star_k_val)\n",
    "        #print('lol')\n",
    "        cycle_time_temp = time.time()-cycle_time\n",
    "        cycle_time_store.append(cycle_time_temp)\n",
    "        #print('Cycle time: ',time.time()-cycle_time)\n",
    "    \n",
    "    return (x_star_k,x_star_k_val)#,xk_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGA TO COMPASS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outputs =[]\\nfor i,cluster in enumerate(final_clusters):\\n    continue\\n    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Outputs =[]\n",
    "for i,cluster in enumerate(final_clusters):\n",
    "    continue\n",
    "    #Outputs.append(simulate(cluster,compass_budget*(1-fitness_vals[i])))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(values):\n",
    "    # Calculate the raw fitness values (inverse of the input values)\n",
    "    raw_fitness = [1 / (value + 1e-6) for value in values]\n",
    "    \n",
    "    # Normalize the raw fitness values so they sum to 1\n",
    "    total_fitness = sum(raw_fitness)\n",
    "    normalized_fitness = [f / total_fitness for f in raw_fitness]\n",
    "    \n",
    "    return normalized_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_cycle_steps=0\n",
    "def ISC(total_budget,alpha,no_of_clusters=no_of_clusters):\n",
    "    \n",
    "    global step_size , step_size_param \n",
    "    global no_of_cycle_steps\n",
    "    clusters,q,r,sol_vals_dict,center_vals = initialize(500,no_of_clusters)\n",
    "    print('total budget: ',total_budget)\n",
    "    print('no of clusters: ', no_of_clusters)\n",
    "    #print('ini')\n",
    "    final_cluster_set=evolution(clusters,sol_vals_dict,center_vals)\n",
    "    #print('evo')\n",
    "    centers_items =  final_cluster_set.keys()\n",
    "    centers = [list(i) for i in centers_items]\n",
    "    #print(centers)\n",
    "    sol_items = final_cluster_set.values()\n",
    "    final_clusters =[]\n",
    "    #print(sol_items)\n",
    "    cost_vals=[]\n",
    "    assign_budgets(total_budget,alpha=alpha)\n",
    "    for i,local_cluster in enumerate(sol_items):\n",
    "        #print(local_cluster)\n",
    "        local_cluster=local_cluster[:2]\n",
    "        local_cluster.append(centers[i])\n",
    "        final_clusters.append(local_cluster)\n",
    "        cost_vals.append(stochastic_cost_function(centers[i]))\n",
    "        #print('-'*20)\n",
    "        #print(final_clusters)\n",
    "    #print(final_clusters)\n",
    "    fitness_vals=fitness_function(cost_vals)\n",
    "    \n",
    "    '''total_costs = np.sum(cost_vals)\n",
    "    for i in range(len(cost_vals)):\n",
    "        fitness_vals.append(abs(total_costs/cost_vals[i]))\n",
    "    '''\n",
    "    print('fitness: ',fitness_vals)\n",
    " \n",
    "    Outputs =[]\n",
    "    step_size_param = step_size_param//2\n",
    "    import time\n",
    "    for i,cluster in enumerate(final_clusters):\n",
    "\n",
    "        print('i=' ,i)\n",
    "        if fitness_vals[i]<0.05:\n",
    "            print('Skipping cluster due to low fitness value')\n",
    "            continue\n",
    "        step_size = step_size_param\n",
    "        comp_time = time.time()\n",
    "        Outputs.append(simulate(cluster,compass_budget*(fitness_vals[i])))\n",
    "        print('No, of cycle steps: ',no_of_cycle_steps)\n",
    "        print('COMPASS time: ',time.time()- comp_time)\n",
    "    import matplotlib.pyplot as plt\n",
    "   \n",
    "    sorted_outputs = sorted(Outputs,key= lambda x:x[1])\n",
    "   # print(sorted_outputs[0])\n",
    "    return sorted_outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(np.arange(len(cycle_time_store)),cycle_time_store)\n",
    "plt.hist(cycle_time_store,bins=50)\n",
    "plt.xticks(np.arange(0,1,0.1))\n",
    "print(np.mean(cycle_time_store))\n",
    "print(len(cycle_time_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.8783955226833"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_cost_function((0, -2, -2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total budget:  300000.0\n",
      "no of clusters:  2\n",
      "clusters: dict_keys([(-29, 11, 7, -28), (-41, 5, 7, -38)])\n",
      "GA Budget over\n",
      "fitness:  [0.5777579704185769, 0.4222420295814232]\n",
      "i= 0\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "x*:  [0, 0, 0, 0]\n",
      "COMPASS Budget Over\n",
      "No, of cycle steps:  244\n",
      "COMPASS time:  105.6598482131958\n",
      "i= 1\n",
      "x*:  [1, 0, 0, 1]\n",
      "COMPASS Budget Over\n",
      "No, of cycle steps:  348\n",
      "COMPASS time:  119.42835116386414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0], 1.2643537495681187)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISC(total_budget,alpha,no_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clustering_outcomes = []\\nimport gc\\nimport matplotlib.pyplot as plt\\n\\n# Iterate over ratio_ga_compass and cluster_count values\\nfor ratio in np.arange(0.6, 0.9, 0.1):  # Include 1.0 in the range\\n    for clusters in range(3, 6):  # cluster_count values from 1 to 5\\n        print(f'ratio_ga_compass = {ratio:.1f}, cluster_count = {clusters}')\\n        \\n        # Run improved_stochastic_clustering 4 times and keep the minimum\\n        best_value = float('inf')\\n        best_configuration = None\\n        for _ in range(4):\\n            print(_)\\n            configuration, performance = ISC(total_budget, ratio, clusters)\\n            if performance < best_value:\\n                best_value = performance\\n                best_configuration = configuration\\n        print('-'*20)\\n        clustering_outcomes.append((ratio, clusters, best_value))\\n        print(f'Best performance after 4 runs: {best_value}')\\n        # Define the variables you want to keep\\n        \\n# Convert clustering_outcomes to a numpy array for easier manipulation\\noutcome_array = np.array(clustering_outcomes)\\n\\n# Create a plot for each ratio value\\nfor ratio in np.unique(outcome_array[:, 0]):\\n    plt.figure(figsize=(10, 6))\\n    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\\n    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o')\\n    \\n    plt.title(f'Best Performance for Ratio={ratio:.1f} (4 runs each)')\\n    plt.xlabel('Number of Clusters')\\n    plt.ylabel('Best Performance Value')\\n    plt.grid(True)\\n    #plt.savefig(f'performance_ratio_{ratio:.1f}.png')\\n    plt.close()\\n\\n# Create a single plot with all ratio values\\nplt.figure(figsize=(12, 8))\\nfor ratio in np.unique(outcome_array[:, 0]):\\n    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\\n    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o', label=f'Ratio={ratio:.1f}')\\n\\nplt.title('Best Performance for Different Ratios and Cluster Counts (4 runs each)')\\nplt.xlabel('Number of Clusters')\\nplt.ylabel('Best Performance Value')\\nplt.legend()\\nplt.grid(True)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clustering_outcomes = []\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over ratio_ga_compass and cluster_count values\n",
    "for ratio in np.arange(0.6, 0.9, 0.1):  # Include 1.0 in the range\n",
    "    for clusters in range(3, 6):  # cluster_count values from 1 to 5\n",
    "        print(f'ratio_ga_compass = {ratio:.1f}, cluster_count = {clusters}')\n",
    "        \n",
    "        # Run improved_stochastic_clustering 4 times and keep the minimum\n",
    "        best_value = float('inf')\n",
    "        best_configuration = None\n",
    "        for _ in range(4):\n",
    "            print(_)\n",
    "            configuration, performance = ISC(total_budget, ratio, clusters)\n",
    "            if performance < best_value:\n",
    "                best_value = performance\n",
    "                best_configuration = configuration\n",
    "        print('-'*20)\n",
    "        clustering_outcomes.append((ratio, clusters, best_value))\n",
    "        print(f'Best performance after 4 runs: {best_value}')\n",
    "        # Define the variables you want to keep\n",
    "        \n",
    "# Convert clustering_outcomes to a numpy array for easier manipulation\n",
    "outcome_array = np.array(clustering_outcomes)\n",
    "\n",
    "# Create a plot for each ratio value\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o')\n",
    "    \n",
    "    plt.title(f'Best Performance for Ratio={ratio:.1f} (4 runs each)')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Best Performance Value')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(f'performance_ratio_{ratio:.1f}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create a single plot with all ratio values\n",
    "plt.figure(figsize=(12, 8))\n",
    "for ratio in np.unique(outcome_array[:, 0]):\n",
    "    ratio_data = outcome_array[outcome_array[:, 0] == ratio]\n",
    "    plt.plot(ratio_data[:, 1], ratio_data[:, 2], marker='o', label=f'Ratio={ratio:.1f}')\n",
    "\n",
    "plt.title('Best Performance for Different Ratios and Cluster Counts (4 runs each)')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Best Performance Value')\n",
    "plt.legend()\n",
    "plt.grid(True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 99, 98, 100],\n",
       " [99, 100, 100, 100],\n",
       " [99, 99, 99, 99],\n",
       " [99, 100, 99, 100],\n",
       " [100, 98, 99, 99],\n",
       " [99, 100, 99, 99]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "get_n_neighbours([100,100,100,100],6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
